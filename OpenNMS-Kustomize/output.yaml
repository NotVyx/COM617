apiVersion: v1
kind: Namespace
metadata:
  name: opennms
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: event-watcher-userW
  namespace: opennms
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: opennms-admins
  namespace: opennms
rules:
- apiGroups:
  - '*'
  resources:
  - '*'
  verbs:
  - '*'
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: opennms-operators
  namespace: opennms
rules:
- apiGroups:
  - ""
  resources:
  - configmaps
  - pods
  - pods/log
  - services
  verbs:
  - get
  - list
  - watch
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: event-watcher-role
rules:
- apiGroups:
  - ""
  resources:
  - pods
  - services
  - events
  verbs:
  - get
  - list
  - watch
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: opennms-admins-binding
  namespace: opennms
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: opennms-admins
subjects:
- apiGroup: rbac.authorization.k8s.io
  kind: Group
  name: onms-admin
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: opennms-operators-binding
  namespace: opennms
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: opennms-operators
subjects:
- apiGroup: rbac.authorization.k8s.io
  kind: Group
  name: onms-operator
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: opennms-storage-binding
  namespace: opennms
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: system:persistent-volume-provisioner
subjects:
- apiGroup: rbac.authorization.k8s.io
  kind: Group
  name: onms-admin
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: event-watcher-binding
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: event-watcher-role
subjects:
- kind: ServiceAccount
  name: event-watcher-user
  namespace: opennms
---
apiVersion: v1
data:
  CASSANDRA_CLUSTER_NAME: OpenNMS
  CASSANDRA_DC: Main
  CASSANDRA_REPLICATION_FACTOR: "1"
  DOMAIN: test
  ELASTIC_INDEX_STRATEGY_FLOWS: daily
  ELASTIC_NUM_SHARDS: "1"
  ELASTIC_REPLICATION_FACTOR: "0"
  KAFKA_NUM_PARTITIONS: "1"
  KAFKA_REPLICATION_FACTOR: "1"
  MINION_LOCATION: Kubernetes
  OPENNMS_INSTANCE_ID: K8S
  TIMEZONE: America/New_York
kind: ConfigMap
metadata:
  annotations:
    owner: agalue@opennms.org
  labels:
    target: opennms
  name: common-settings
  namespace: opennms
---
apiVersion: v1
data:
  actions.yaml: |+
    actions:
      1:
        action: forcemerge
        description: Force merge Netflow indices
        options:
          max_num_segments: 1
          delay: 120
          timneout_override:
          continue_if_exception: False
          disable_action: False
        filters:
        - filtertype: pattern
          kind: prefix
          value: netflow-
          exclude:
        - filtertype: age
          source: name
          direction: older
          timestring: '%Y-%m-%d-%H'
          unit: hours
          unit_count: 12
          exclude:
        - filtertype: forcemerged
          max_num_segments: 1
          exclude:
      2:
        action: delete_indices
        description: Delete indices older than 30 days.
        options:
          ignore_empty_list: True
          disable_action: False
        filters:
        - filtertype: pattern
          kind: prefix
          value: netflow-
        - filtertype: age
          source: name
          direction: older
          timestring: '%Y-%m-%d-%H'
          unit: hours
          unit_count: 720

  config.yaml: |
    client:
      hosts:
      - esdata.opennms.svc.cluster.local
      port: 9200
      url_prefix:
      use_ssl: False
      certificate:
      client_cert:
      client_key:
      ssl_no_validate: False
      http_auth:
      timeout: 30
      master_only: True
    logging:
      loglevel: INFO
      logfile:
      logformat: default
      blacklist: ['elasticsearch', 'urllib3']
kind: ConfigMap
metadata:
  labels:
    app: curator
  name: curator-config
  namespace: opennms
---
apiVersion: v1
data:
  hasura.sql: |+
    CREATE USER hasurauser WITH PASSWORD 'hasurauser';
    CREATE EXTENSION IF NOT EXISTS pgcrypto;
    CREATE SCHEMA IF NOT EXISTS hdb_catalog;
    CREATE SCHEMA IF NOT EXISTS hdb_views;
    ALTER SCHEMA hdb_catalog OWNER TO hasurauser;
    ALTER SCHEMA hdb_views OWNER TO hasurauser;
    GRANT SELECT ON ALL TABLES IN SCHEMA information_schema TO hasurauser;
    GRANT SELECT ON ALL TABLES IN SCHEMA pg_catalog TO hasurauser;
    GRANT ALL ON ALL TABLES IN SCHEMA public TO hasurauser;
    GRANT ALL ON ALL SEQUENCES IN SCHEMA public TO hasurauser;

kind: ConfigMap
metadata:
  labels:
    app: hasura
  name: hasura-config
  namespace: opennms
---
apiVersion: v1
data:
  create-topics.sh: |-
    #!/bin/bash
    # @author Alejandro Galue <agalue@opennms.org>

    CFG="/tmp/client.properties"
    cat <<EOF > $CFG
    security.protocol=SASL_PLAINTEXT
    sasl.mechanism=PLAIN
    sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username="$KAFKA_CLIENT_USER" password="$KAFKA_CLIENT_PASSWORD";
    EOF

    for TOPIC in $CREATE_TOPICS; do
      echo "Creating topic $TOPIC ..."
      JMX_PORT='' kafka-topics.sh --bootstrap-server $KAFKA_SERVER:9092 \
        --command-config=$CFG \
        --create --if-not-exists --topic $TOPIC \
        --partitions $KAFKA_CFG_NUM_PARTITIONS \
        --replication-factor $KAFKA_CFG_DEFAULT_REPLICATION_FACTOR
    done
  grafana-init.sh: |
    #!/bin/sh
    # @author Alejandro Galue <agalue@opennms.org>
    #
    # Purpose:
    # - Create a PostgreSQL database and user for grafana, if it doesn't exist.
    #
    # Mandatory Environment variables:
    # - PGHOST
    # - PGPORT
    # - PGUSER
    # - PGPASSWORD
    # - GF_DATABASE_NAME
    # - GF_DATABASE_USER
    # - GF_DATABASE_PASSWORD

    until pg_isready; do
      echo "$(date) Waiting for postgresql host ${PGHOST}..."
      sleep 2
    done

    if psql -lqt | cut -d \| -f 1 | grep -qw "${GF_DATABASE_NAME}"; then
      TABLES=$(psql -qtAX -d "${GF_DATABASE_NAME}" -c "select count(*) from  pg_stat_user_tables;")
      echo "Grafana database already exists on ${PGHOST}."
      echo "There are ${TABLES} tables on it, skipping..."
    else
      echo "Creating grafana user and database on ${PGHOST}..."
      createdb -E UTF-8 "${GF_DATABASE_NAME}"
      createuser "${GF_DATABASE_USER}"
      psql -c "alter role ${GF_DATABASE_USER} with password '${GF_DATABASE_PASSWORD}';"
      psql -c "alter user ${GF_DATABASE_USER} set search_path to ${GF_DATABASE_NAME},public;"
      psql -c "grant all on database ${GF_DATABASE_NAME} to ${GF_DATABASE_USER};"
    fi
  onms-alec-init.sh: |
    #!/bin/bash
    # @author Alejandro Galue <agalue@opennms.org>
    #
    # ALEC is required only for advanced alarms correlation.
    #
    # Requirements:
    # - Horizon 27 or newer is required.
    # - ALEC 1.1.0 or newer is required.
    # - Overlay volume mounted at /etc-overlay
    #
    # Environment variables:
    # - INSTANCE_ID
    # - ZOOKEEPER_SERVER
    # - KAFKA_SERVER
    # - KAFKA_SASL_USERNAME
    # - KAFKA_SASL_PASSWORD

    # To avoid issues with OpenShift
    umask 002

    OVERLAY=/etc-overlay
    SENTINEL_HOME=/opt/sentinel

    # Configure the instance ID
    # Required when having multiple OpenNMS backends sharing the same Kafka cluster.
    CUSTOM_PROPERTIES=${OVERLAY}/custom.system.properties
    if [[ ${INSTANCE_ID} ]]; then
      echo "Configuring Instance ID..."
      cat <<EOF >> ${CUSTOM_PROPERTIES}
    # Used for Kafka Topics
    org.opennms.instance.id=${INSTANCE_ID}
    EOF
    else
      INSTANCE_ID="OpenNMS"
    fi

    FEATURES_DIR=${OVERLAY}/featuresBoot.d
    mkdir -p ${FEATURES_DIR}
    echo "Configuring Features..."

    cat <<EOF > ${FEATURES_DIR}/alec.boot
    sentinel-core
    sentinel-coordination-zookeeper
    alec-sentinel-distributed wait-for-kar=opennms-alec-plugin
    EOF

    if [[ ${ZOOKEEPER_SERVER} ]]; then
      echo "Configure ZooKeeper for distributed coordination..."

      cat <<EOF > ${OVERLAY}/org.opennms.features.distributed.coordination.zookeeper.cfg
    connectString=${ZOOKEEPER_SERVER}:2181
    EOF
    fi

    if [[ ${KAFKA_SERVER} ]]; then
      echo "Configuring Kafka..."

      if [[ ${KAFKA_SASL_USERNAME} && ${KAFKA_SASL_PASSWORD} ]]; then
        read -r -d '' KAFKA_SASL <<EOF
    security.protocol=SASL_PLAINTEXT
    sasl.mechanism=PLAIN
    sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username="${KAFKA_SASL_USERNAME}" password="${KAFKA_SASL_PASSWORD}";
    EOF
      fi

      cat <<EOF > ${OVERLAY}/org.opennms.core.ipc.sink.kafka.consumer.cfg
    bootstrap.servers=${KAFKA_SERVER}:9092
    ${KAFKA_SASL}
    EOF

      cat <<EOF > ${OVERLAY}/org.opennms.alec.datasource.opennms.kafka.producer.cfg
    bootstrap.servers=${KAFKA_SERVER}:9092
    ${KAFKA_SASL}
    EOF

      cat <<EOF > ${OVERLAY}/org.opennms.alec.datasource.opennms.kafka.streams.cfg
    bootstrap.servers=${KAFKA_SERVER}:9092
    application.id=${INSTANCE_ID}_alec_datasource
    commit.interval.ms=5000
    ${KAFKA_SASL}
    EOF

      cat <<EOF > ${OVERLAY}/org.opennms.alec.datasource.opennms.kafka.cfg
    # Make sure to configure the topics on OpenNMS the same way
    eventSinkTopic=${INSTANCE_ID}.Sink.Events
    inventoryTopic=${INSTANCE_ID}_alec_inventory
    nodeTopic=${INSTANCE_ID}_nodes
    alarmTopic=${INSTANCE_ID}_alarms
    alarmFeedbackTopic=${INSTANCE_ID}_alarms_feedback
    edgesTopic=${INSTANCE_ID}_edges
    EOF
    fi
  onms-core-init.sh: |
    #!/bin/bash
    # @author Alejandro Galue <agalue@opennms.org>
    #
    # Requirements:
    # - Horizon 27 or newer is required.
    # - Must run within a init-container based on the opennms/horizon image.
    #   Version must match the runtime container.
    # - Target configuration volume at /opennms-etc
    # - rsync must be pre-installed on the chosen image.
    #
    # Purpose:
    # - Initialize the config directory on the volume only once.
    # - Apply mandatory configuration changes based on the provided variables.
    # - Be on guard against upgrades, by always overriding Karaf/OSGi configuration
    #   files from the source, with embedded versions for multiple components.
    #
    # Warning:
    # - Multiple assumptions are made on Newts/Cassandra configuration.
    # - Do not include any file that can be changed through the WebUI or is intended
    #   to represent customers/users needs. The configuration directory will be
    #   behind a persistent volume, precisely to save user changes.
    #
    # Pending:
    # - If the name of the newts keyspace is changed, poller-configuration.xml and the JMX
    #   mbeans must be updated as well.
    #
    # External Environment variables:
    # - INSTANCE_ID
    # - FEATURES_LIST
    # - ENABLE_ALEC
    # - KAFKA_SERVER
    # - KAFKA_SASL_USERNAME
    # - KAFKA_SASL_PASSWORD
    # - CASSANDRA_SERVER
    # - CASSANDRA_DC
    # - CASSANDRA_REPLICATION_FACTOR
    # - ELASTIC_SERVER
    # - ELASTIC_PASSWORD
    # - ELASTIC_REPLICATION_FACTOR
    # - ELASTIC_NUM_SHARDS
    # - ELASTIC_INDEX_STRATEGY_FLOWS
    # - ELASTIC_INDEX_STRATEGY_REST
    # - ELASTIC_INDEX_STRATEGY_ALARMS
    # - KAFKA_MAX_MESSAGE_SIZE
    # - JAEGER_AGENT_HOST
    # - FORWARD_METRICS

    # To avoid issues with OpenShift
    umask 002

    command -v rsync >/dev/null 2>&1 || { echo >&2 "rsync is required but it's not installed. Aborting."; exit 1; }

    ELASTIC_INDEX_STRATEGY_FLOWS=${ELASTIC_INDEX_STRATEGY_FLOWS-daily}
    ELASTIC_INDEX_STRATEGY_REST=${ELASTIC_INDEX_STRATEGY_REST-monthly}
    ELASTIC_INDEX_STRATEGY_ALARMS=${ELASTIC_INDEX_STRATEGY_ALARMS-monthly}
    ELASTIC_REPLICATION_FACTOR=${ELASTIC_REPLICATION_FACTOR-2}
    ELASTIC_NUM_SHARDS=${ELASTIC_NUM_SHARDS-6}
    KAFKA_MAX_MESSAGE_SIZE=${KAFKA_MAX_MESSAGE_SIZE-5000000}
    FORWARD_METRICS=${FORWARD_METRICS-true}

    CONFIG_DIR=/opennms-etc
    BACKUP_ETC=/opt/opennms/etc
    KEYSPACE=$(echo ${INSTANCE_ID-onms}_newts | tr '[:upper:]' '[:lower:]')
    KARAF_FILES=( \
    "config.properties" \
    "startup.properties" \
    "custom.properties" \
    "jre.properties" \
    "profile.cfg" \
    "jmx.acl.*" \
    "org.apache.felix.*" \
    "org.apache.karaf.*" \
    "org.ops4j.pax.url.mvn.cfg" \
    )

    # Show permissions (debug purposes)
    ls -ld ${CONFIG_DIR}

    # Initialize configuration directory
    if [ ! -f ${CONFIG_DIR}/configured ]; then
      echo "Initializing configuration directory for the first time ..."
      rsync -arO --no-perms ${BACKUP_ETC}/ ${CONFIG_DIR}/

      echo "Disabling data choices"
      cat <<EOF > ${CONFIG_DIR}/org.opennms.features.datachoices.cfg
    enabled=false
    acknowledged-by=admin
    acknowledged-at=Mon Jan 01 00\:00\:00 EDT 2018
    EOF

      echo "Initialize default foreign source definition"
      cat <<EOF > ${CONFIG_DIR}/default-foreign-source.xml
    <foreign-source xmlns="http://xmlns.opennms.org/xsd/config/foreign-source" name="default" date-stamp="2018-01-01T00:00:00.000-05:00">
      <scan-interval>1d</scan-interval>
      <detectors>
        <detector name="ICMP" class="org.opennms.netmgt.provision.detector.icmp.IcmpDetector"/>
        <detector name="SNMP" class="org.opennms.netmgt.provision.detector.snmp.SnmpDetector"/>
      </detectors>
      <policies>
        <policy name="Do Not Persist Discovered IPs" class="org.opennms.netmgt.provision.persist.policies.MatchingIpInterfacePolicy">
          <parameter key="action" value="DO_NOT_PERSIST"/>
          <parameter key="matchBehavior" value="NO_PARAMETERS"/>
        </policy>
        <policy name="Enable Data Collection" class="org.opennms.netmgt.provision.persist.policies.MatchingSnmpInterfacePolicy">
          <parameter key="action" value="ENABLE_COLLECTION"/>
          <parameter key="matchBehavior" value="ANY_PARAMETER"/>
          <parameter key="ifOperStatus" value="1"/>
        </policy>
      </policies>
    </foreign-source>
    EOF
    else
      echo "Previous configuration found. Synchronizing only new files..."
      rsync -aruO --no-perms ${BACKUP_ETC}/ ${CONFIG_DIR}/
    fi

    # Guard against application upgrades
    MANDATORY=/tmp/opennms-mandatory
    mkdir -p ${MANDATORY}
    for file in "${KARAF_FILES[@]}"; do
      echo "Backing up ${file} to ${MANDATORY}..."
      cp --force ${BACKUP_ETC}/${file} ${MANDATORY}/
    done
    # WARNING: if the volume behind CONFIG_DIR doesn't have the right permissions, the following fails
    echo "Overriding mandatory files from ${MANDATORY}..."
    rsync -aO --no-perms ${MANDATORY}/ ${CONFIG_DIR}/

    # Configure the instance ID
    # Required when having multiple OpenNMS backends sharing the same Kafka cluster.
    if [[ ${INSTANCE_ID} ]]; then
      echo "Configuring Instance ID..."
      cat <<EOF > ${CONFIG_DIR}/opennms.properties.d/instanceid.properties
    # Used for Kafka Topics
    org.opennms.instance.id=${INSTANCE_ID}
    EOF
    else
      INSTANCE_ID="OpenNMS"
    fi

    cat <<EOF > ${CONFIG_DIR}/opennms.properties.d/rrd.properties
    org.opennms.rrd.storeByGroup=true
    org.opennms.rrd.storeByForeignSource=true
    EOF

    cat <<EOF > ${CONFIG_DIR}/opennms.properties.d/collectd.properties
    # To get data as close as possible to PDP
    org.opennms.netmgt.collectd.strictInterval=true
    # To only retrieve data from the SNMP Interfaces that has snmpCollect=true
    org.opennms.netmgt.collectd.SnmpCollector.limitCollectionToInstances=true
    EOF

    # Required changes in order to use HTTPS through Ingress
    cat <<EOF > ${CONFIG_DIR}/opennms.properties.d/webui.properties
    opennms.web.base-url=https://%x%c/
    org.opennms.security.disableLoginSuccessEvent=true
    org.opennms.web.defaultGraphPeriod=last_2_hour
    EOF

    # Enable OSGi features
    if [[ ${FEATURES_LIST} ]]; then
      echo "Enabling features: ${FEATURES_LIST} ..."
      LAST_ENTRY="opennms-karaf-health"
      FEATURES_CFG=${CONFIG_DIR}/org.apache.karaf.features.cfg
      sed -r -i "s/^  $LAST_ENTRY.*/  ${FEATURES_LIST},$LAST_ENTRY/" ${FEATURES_CFG}
    fi

    # Enable ALEC (distributed mode)
    if [[ ${ENABLE_ALEC} ]]; then
      echo "Enabling ALEC (distributed mode)..."
      cat <<EOF > ${CONFIG_DIR}/featuresBoot.d/alec.boot
    alec-opennms-distributed wait-for-kar=opennms-alec-plugin
    EOF
    fi

    # Enable Syslogd
    sed -r -i '/enabled="false"/{$!{N;s/ enabled="false"[>]\n(.*OpenNMS:Name=Syslogd.*)/>\n\1/}}' ${CONFIG_DIR}/service-configuration.xml

    # Disable Telemetryd as BMP, flows, and streaming telemetry data will be managed by sentinels
    sed -i -r '/opennms-flows/d' ${CONFIG_DIR}/org.apache.karaf.features.cfg
    sed -i 'N;s/service.*\n\(.*Telemetryd\)/service enabled="false">\n\1/;P;D' ${CONFIG_DIR}/service-configuration.xml

    # Enable tracing with jaeger
    if [[ ${JAEGER_AGENT_HOST} ]]; then
      cat <<EOF > $CONFIG_DIR/opennms.properties.d/jaeger.properties
    org.opennms.core.tracer=jaeger
    JAEGER_AGENT_HOST=${JAEGER_AGENT_HOST}
    EOF
      echo "opennms-core-tracing-jaeger" > ${CONFIG_DIR}/featuresBoot.d/jaeger.boot
    fi

    # Configure Sink and RPC to use Kafka, and the Kafka Producer.
    if [[ ${KAFKA_SERVER} ]]; then
      echo "Configuring Kafka..."

      cat <<EOF > ${CONFIG_DIR}/opennms.properties.d/event-sink.properties
    org.opennms.netmgt.eventd.sink.enable=true
    EOF

      cat <<EOF > ${CONFIG_DIR}/opennms.properties.d/amq.properties
    org.opennms.activemq.broker.disable=true
    EOF

      cat <<EOF > ${CONFIG_DIR}/opennms.properties.d/kafka.properties
    # Sink
    org.opennms.core.ipc.sink.initialSleepTime=60000
    org.opennms.core.ipc.sink.strategy=kafka
    org.opennms.core.ipc.sink.kafka.bootstrap.servers=${KAFKA_SERVER}:9092
    org.opennms.core.ipc.sink.kafka.group.id=${INSTANCE_ID}-Sink

    # Sink Consumer (verify Kafka broker configuration)
    org.opennms.core.ipc.sink.kafka.session.timeout.ms=30000
    org.opennms.core.ipc.sink.kafka.max.poll.records=50
    org.opennms.core.ipc.sink.kafka.max.partition.fetch.bytes=${KAFKA_MAX_MESSAGE_SIZE}

    # RPC
    org.opennms.core.ipc.rpc.strategy=kafka
    org.opennms.core.ipc.rpc.kafka.bootstrap.servers=${KAFKA_SERVER}:9092
    org.opennms.core.ipc.rpc.kafka.ttl=30000
    org.opennms.core.ipc.rpc.kafka.single-topic=true
    org.opennms.core.ipc.rpc.kafka.group.id=${INSTANCE_ID}-RPC

    # RPC Consumer (verify Kafka broker configuration)
    org.opennms.core.ipc.rpc.kafka.request.timeout.ms=30000
    org.opennms.core.ipc.rpc.kafka.session.timeout.ms=30000
    org.opennms.core.ipc.rpc.kafka.max.poll.records=50
    org.opennms.core.ipc.rpc.kafka.max.partition.fetch.bytes=${KAFKA_MAX_MESSAGE_SIZE}
    org.opennms.core.ipc.rpc.kafka.auto.offset.reset=latest

    # RPC Producer (verify Kafka broker configuration)
    org.opennms.core.ipc.rpc.kafka.acks=0
    org.opennms.core.ipc.rpc.kafka.linger.ms=5
    org.opennms.core.ipc.rpc.kafka.compression.type=zstd
    org.opennms.core.ipc.rpc.kafka.max.request.size=${KAFKA_MAX_MESSAGE_SIZE}
    EOF

      if [[ ${KAFKA_SASL_USERNAME} && ${KAFKA_SASL_PASSWORD} ]]; then
        cat <<EOF >> ${CONFIG_DIR}/opennms.properties.d/kafka.properties

    # Authentication
    org.opennms.core.ipc.sink.kafka.security.protocol=SASL_PLAINTEXT
    org.opennms.core.ipc.sink.kafka.sasl.mechanism=PLAIN
    org.opennms.core.ipc.sink.kafka.sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username="${KAFKA_SASL_USERNAME}" password="${KAFKA_SASL_PASSWORD}";
    org.opennms.core.ipc.rpc.kafka.security.protocol=SASL_PLAINTEXT
    org.opennms.core.ipc.rpc.kafka.sasl.mechanism=PLAIN
    org.opennms.core.ipc.rpc.kafka.sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username="${KAFKA_SASL_USERNAME}" password="${KAFKA_SASL_PASSWORD}";
    EOF
      fi

      if [[ ${FEATURES_LIST} == *"opennms-kafka-producer"* ]]; then
        cat <<EOF > $CONFIG_DIR/org.opennms.features.kafka.producer.client.cfg
    bootstrap.servers=$KAFKA_SERVER:9092
    acks=1
    linger.ms=5
    compression.type=zstd
    timeout.ms=30000
    max.request.size=${KAFKA_MAX_MESSAGE_SIZE}
    state.dir=/opennms-data/kafka
    EOF
        if [[ ${KAFKA_SASL_USERNAME} && ${KAFKA_SASL_PASSWORD} ]]; then
          cat <<EOF >> $CONFIG_DIR/org.opennms.features.kafka.producer.client.cfg
    security.protocol=SASL_PLAINTEXT
    sasl.mechanism=PLAIN
    sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username="${KAFKA_SASL_USERNAME}" password="${KAFKA_SASL_PASSWORD}";
    EOF
        fi
        # Make sure to enable only what's needed for your use case
        SUPPRESS_INC_ALARMS="true"
        if [[ ${ENABLE_ALEC} ]]; then
          SUPPRESS_INC_ALARMS="false"
        fi
        cat <<EOF > ${CONFIG_DIR}/org.opennms.features.kafka.producer.cfg
    topologyProtocols=bridge,cdp,isis,lldp,ospf
    suppressIncrementalAlarms=${SUPPRESS_INC_ALARMS}
    forward.metrics=${FORWARD_METRICS}
    nodeRefreshTimeoutMs=300000
    kafkaSendQueueCapacity=1000
    numEventListenerThreads=4
    # Alarm Synchronization (Streams Application; mandatory for ALEC; requires volume to store data)
    alarmSync=true
    # Topic Names
    nodeTopic=${INSTANCE_ID}_nodes
    alarmTopic=${INSTANCE_ID}_alarms
    eventTopic=${INSTANCE_ID}_events
    metricTopic=${INSTANCE_ID}_metrics
    alarmFeedbackTopic=${INSTANCE_ID}_alarms_feedback
    topologyVertexTopic=${INSTANCE_ID}_topology_vertices
    topologyEdgeTopic=${INSTANCE_ID}_edges
    EOF
      fi
    fi

    # Configure Newts (works with either Cassandra or ScyllaDB)
    if [[ ${CASSANDRA_SERVER} ]]; then
      echo "Configuring Newts..."
      cat <<EOF > ${CONFIG_DIR}/opennms.properties.d/newts.properties
    # About the properties:
    # - ttl (1 year expressed in ms) should be consistent with the TWCS settings on newts.cql
    # - ring_buffer_size and cache.max_entries should be consistent with the expected load and heap size
    #
    # About the keyspace (CQL schema):
    # - The value of compaction_window_size should be consistent with the chosen TTL
    # - The number of SSTables will be the TTL/compaction_window_size (52 for 1 year)

    org.opennms.timeseries.strategy=newts
    org.opennms.newts.config.hostname=${CASSANDRA_SERVER}
    org.opennms.newts.config.keyspace=${KEYSPACE}
    org.opennms.newts.config.port=9042
    org.opennms.newts.config.read_consistency=ONE
    org.opennms.newts.config.write_consistency=ANY

    org.opennms.newts.config.resource_shard=604800
    org.opennms.newts.config.ttl=31540000

    org.opennms.newts.config.cache.priming.enable=true
    org.opennms.newts.config.cache.priming.block_ms=60000

    # The following settings most be tuned in production
    org.opennms.newts.config.writer_threads=2
    org.opennms.newts.config.ring_buffer_size=131072
    org.opennms.newts.config.cache.max_entries=131072
    EOF

      # Required only when collecting data every 30 seconds
      echo "Configuring Optional Newts Settings..."
      cat <<EOF >> $CONFIG_DIR/opennms.properties.d/newts.properties
    org.opennms.newts.query.minimum_step=30000
    org.opennms.newts.query.heartbeat=450000
    EOF

      # Fixing polling/collection settings
      sed -r -i "s/keyspace=newts/keyspace=${KEYSPACE}/" ${CONFIG_DIR}/jmx-datacollection-config.d/cassandra30x-newts.xml
      sed -r -i "s/keyspace=newts/keyspace=${KEYSPACE}/" ${CONFIG_DIR}/poller-configuration.xml
      sed -r -i "s/cassandra-username/cassandra/" ${CONFIG_DIR}/poller-configuration.xml
      sed -r -i "s/cassandra-password/cassandra/" ${CONFIG_DIR}/poller-configuration.xml
      sed -r -i "s/cassandra-username/cassandra/" ${CONFIG_DIR}/collectd-configuration.xml
      sed -r -i "s/cassandra-password/cassandra/" ${CONFIG_DIR}/collectd-configuration.xml
    fi

    if [[ ${CASSANDRA_REPLICATION_FACTOR} ]]; then
      echo "Building Newts Schema for Cassandra/ScyllaDB (assuming 1 year of retention/TTL)..."
      cat <<EOF > ${CONFIG_DIR}/newts.cql
    CREATE KEYSPACE IF NOT EXISTS ${KEYSPACE} WITH replication = {'class' : 'NetworkTopologyStrategy', '${CASSANDRA_DC}' : ${CASSANDRA_REPLICATION_FACTOR} };

    CREATE TABLE IF NOT EXISTS ${KEYSPACE}.samples (
      context text,
      partition int,
      resource text,
      collected_at timestamp,
      metric_name text,
      value blob,
      attributes map<text, text>,
      PRIMARY KEY((context, partition, resource), collected_at, metric_name)
    ) WITH compaction = {
      'compaction_window_size': '7',
      'compaction_window_unit': 'DAYS',
      'expired_sstable_check_frequency_seconds': '86400',
      'class': 'org.apache.cassandra.db.compaction.TimeWindowCompactionStrategy'
    } AND gc_grace_seconds = 604800;

    CREATE TABLE IF NOT EXISTS ${KEYSPACE}.terms (
      context text,
      field text,
      value text,
      resource text,
      PRIMARY KEY((context, field, value), resource)
    );

    CREATE TABLE IF NOT EXISTS ${KEYSPACE}.resource_attributes (
      context text,
      resource text,
      attribute text,
      value text,
      PRIMARY KEY((context, resource), attribute)
    );

    CREATE TABLE IF NOT EXISTS ${KEYSPACE}.resource_metrics (
      context text,
      resource text,
      metric_name text,
      PRIMARY KEY((context, resource), metric_name)
    );
    EOF
    fi

    # Configure Elasticsearch for Flow processing and for the event forwarder
    if [[ ${ELASTIC_SERVER} ]]; then
      PREFIX=$(echo ${INSTANCE_ID} | tr '[:upper:]' '[:lower:]')-

      read -r -d '' ES_COMMON <<EOF
    # Common Settings
    elasticUrl=http://${ELASTIC_SERVER}:9200
    globalElasticUser=elastic
    globalElasticPassword=${ELASTIC_PASSWORD}
    indexPrefix=${PREFIX}
    connTimeout=30000
    readTimeout=300000
    retries=1
    nodeDiscovery=true
    nodeDiscoveryFrequency=3600

    # The following settings should be consistent with your ES cluster
    settings.index.number_of_shards=${ELASTIC_NUM_SHARDS}
    settings.index.number_of_replicas=${ELASTIC_REPLICATION_FACTOR}

    # Custom Settings
    EOF

      echo "Configuring Elasticsearch for Flows..."
      cat <<EOF > ${CONFIG_DIR}/org.opennms.features.flows.persistence.elastic.cfg
    ${ES_COMMON}
    elasticIndexStrategy=${ELASTIC_INDEX_STRATEGY_FLOWS}
    EOF

      if [[ ${FEATURES_LIST} == *"opennms-es-rest"* ]]; then
        echo "Configuring Elasticsearch Event Forwarder..."
        cat <<EOF > ${CONFIG_DIR}/org.opennms.plugin.elasticsearch.rest.forwarder.cfg
    ${ES_COMMON}
    elasticIndexStrategy=${ELASTIC_INDEX_STRATEGY_REST}
    groupOidParameters=true
    logAllEvents=true
    EOF
      fi

      if [[ ${FEATURES_LIST} == *"opennms-alarm-history-elastic"* ]]; then
        echo "Configuring Alarm History Forwarder..."
        cat <<EOF > ${CONFIG_DIR}/org.opennms.features.alarms.history.elastic.cfg
    ${ES_COMMON}
    elasticIndexStrategy=${ELASTIC_INDEX_STRATEGY_ALARMS}
    EOF
      fi

      if [[ ${FEATURES_LIST} == *"opennms-situation-feedback"* ]]; then
        echo "Configuring Situations Feedback..."
        cat <<EOF > ${CONFIG_DIR}/org.opennms.features.situationfeedback.persistence.elastic.cfg
    ${ES_COMMON}
    elasticIndexStrategy=monthly
    EOF
      fi
    fi

    # Configure NXOS Resource Types
    echo "Configuring NXOS resource types..."
    cat <<EOF > ${CONFIG_DIR}/resource-types.d/nxos-intf-resources.xml
    <?xml version="1.0"?>
    <resource-types>
      <resourceType name="nxosIntf" label="Nxos Interface" resourceLabel="\${index}">
        <persistenceSelectorStrategy class="org.opennms.netmgt.collection.support.PersistAllSelectorStrategy"/>
        <storageStrategy class="org.opennms.netmgt.collection.support.IndexStorageStrategy"/>
      </resourceType>
    </resource-types>
    EOF

    # Configure K8s Event Watcher
    cat <<EOF > ${CONFIG_DIR}/events/kubernetes.events.xml
    <events xmlns="http://xmlns.opennms.org/xsd/eventconf">
      <event>
        <uei>uei.opennms.org/kubernetes/event/Warning</uei>
        <event-label>Kubernetes Warning Event</event-label>
        <descr>Received event %parm[reason]% on %parm[kind]% %parm[name]% from namespace %parm[namespace]% at %parm[creationTimestamp]%, originated on worker node %parm[nodeName]%: %parm[message]%</descr>
        <logmsg dest="logndisplay">%parm[message]%</logmsg>
        <severity>Minor</severity>
      </event>
      <event>
        <uei>uei.opennms.org/kubernetes/pod/ADDED</uei>
        <event-label>Kubernetes Pod Added Event</event-label>
        <descr>Pod %parm[name]% has been added to namespace %parm[namespace]% at %parm[creationTimestamp]%</descr>
        <logmsg dest="logndisplay">Pod %parm[name]% added to namespace %parm[namespace]%</logmsg>
        <severity>Normal</severity>
      </event>
      <event>
        <uei>uei.opennms.org/kubernetes/pod/DELETED</uei>
        <event-label>Kubernetes Pod Deleted Event</event-label>
        <descr>Pod %parm[name]% has been removed from namespace %parm[namespace]% at %parm[creationTimestamp]%</descr>
        <logmsg dest="logndisplay">Pod %parm[name]% removed from namespace %parm[namespace]%</logmsg>
        <severity>Warning</severity>
      </event>
      <event>
        <uei>uei.opennms.org/kubernetes/service/ADDED</uei>
        <event-label>Kubernetes Service Added Event</event-label>
        <descr>Service %parm[name]% has been added to namespace %parm[namespace]% at %parm[creationTimestamp]%</descr>
        <logmsg dest="logndisplay">Service %parm[name]% added to namespace %parm[namespace]%</logmsg>
        <severity>Normal</severity>
      </event>
      <event>
        <uei>uei.opennms.org/kubernetes/service/DELETED</uei>
        <event-label>Kubernetes Service Deleted Event</event-label>
        <descr>Service %parm[name]% has been removed from namespace %parm[namespace]% at %parm[creationTimestamp]%</descr>
        <logmsg dest="logndisplay">Service %parm[name]% removed from namespace %parm[namespace]%</logmsg>
        <severity>Warning</severity>
      </event>
    </events>
    EOF
    if ! grep -q kubernetes.events.xml ${CONFIG_DIR}/eventconf.xml; then
      sed -r -i '/[<].global[>]/a <event-file>events/kubernetes.events.xml</event-file>' ${CONFIG_DIR}/eventconf.xml
    fi

    # Cleanup temporary requisition files:
    rm -f ${CONFIG_DIR}/imports/pending/*.xml.*
    rm -f ${CONFIG_DIR}/foreign-sources/pending/*.xml.*

    # Force to execute runjava and the install script
    touch ${CONFIG_DIR}/do-upgrade

    # Fix permissions when executing the script as root
    if [[ "$(id -u)" == "0" ]]; then
      chown -R opennms:opennms ${CONFIG_DIR}
    fi
  onms-helm-init.sh: |
    #!/bin/sh
    # @author Alejandro Galue <agalue@opennms.org>
    #
    # Purpose:
    # - Enable the Helm plugin and initialize the data sources, if Helm is disable.
    #
    # Mandatory Environment variables:
    # - GF_SECURITY_ADMIN_PASSWORD
    # - GRAFANA_URL

    GRAFANA_AUTH="admin:${GF_SECURITY_ADMIN_PASSWORD}"
    HELM_URL="${GRAFANA_URL}/api/plugins/opennms-helm-app/settings"
    DS_URL="${GRAFANA_URL}/api/datasources"

    JSON_FILE=/tmp/data.json
    cat <<EOF > ${JSON_FILE}
    {
      "name": "opennms-performance",
      "type": "opennms-helm-performance-datasource",
      "access": "proxy",
      "url": "${ONMS_URL}",
      "basicAuth": true,
      "basicAuthUser": "${ONMS_USER}",
      "basicAuthPassword": "${ONMS_PASSWD}"
    }
    EOF

    until curl --output /dev/null --silent --head --fail "${GRAFANA_URL}"; do
      echo "$(date) Waiting for grafana to be ready on ${GRAFANA_URL} ..."
      sleep 5
    done

    echo "$(date) Checking if OpenNMS Helm is enabled..."
    if curl -u "${GRAFANA_AUTH}" "${HELM_URL}" 2>/dev/null | grep -q '"enabled":false'; then
      echo
      echo "$(date) Enabling OpenNMS Helm..."
      curl -u "${GRAFANA_AUTH}" -XPOST "${HELM_URL}" -d "id=opennms-helm-app&enabled=true" 2>/dev/null
      echo
      echo "$(date) Adding data source for performance metrics..."
      curl -u "${GRAFANA_AUTH}" -H 'Content-Type: application/json' -XPOST -d @${JSON_FILE} "${DS_URL}" 2>/dev/null
      echo
      echo "$(date) Adding data source for entities..."
      sed -i -r 's/-performance/-entity/g' ${JSON_FILE}
      curl -u "${GRAFANA_AUTH}" -H 'Content-Type: application/json' -XPOST -d @${JSON_FILE} "${DS_URL}" 2>/dev/null
      echo
      echo "$(date) Adding data source for flows..."
      sed -i -r 's/-entity/-flow/g' ${JSON_FILE}
      curl -u "${GRAFANA_AUTH}" -H 'Content-Type: application/json' -XPOST -d @${JSON_FILE} "${DS_URL}" 2>/dev/null
      echo
    else
      echo "$(date) OpenNMS Helm was already enabled and configured."
    fi

    rm -f ${JSON_FILE}
  onms-minion-init.sh: |
    #!/bin/bash
    # @author Alejandro Galue <agalue@opennms.org>
    #
    # Requirements:
    # - Horizon 27 or newer is required
    # - Overlay volume mounted at /etc-overlay
    #
    # Purpose:
    # - Configure the instance ID, SNMP4J and Kafka (for RPC and Sink)
    # - Configure listeneres for Traps, Syslog, and Telemetry (on fixed ports)
    #
    # Warnings:
    # - Even if the Kafka cluster is configured to manage large messages,
    #   another source of big messages is the "batch.size" on Sink topics.
    #   On large deployments, this might have to be reduced.
    #
    # Environment variables:
    # - INSTANCE_ID
    # - OPENNMS_HTTP_USER
    # - OPENNMS_HTTP_PASS
    # - KAFKA_SERVER
    # - KAFKA_SASL_USERNAME
    # - KAFKA_SASL_PASSWORD
    # - KAFKA_MAX_MESSAGE_SIZE
    # - SINGLE_PORT
    # - JAEGER_AGENT_HOST
    # - DNS_LOOKUPS_ENABLED
    # - DNS_SERVERS

    # To avoid issues with OpenShift
    umask 002

    KAFKA_MAX_MESSAGE_SIZE=${KAFKA_MAX_MESSAGE_SIZE-5000000}

    OVERLAY=/etc-overlay
    CUSTOM_PROPERTIES=${OVERLAY}/custom.system.properties

    ### Basic Settings

    FEATURES_DIR=${OVERLAY}/featuresBoot.d
    mkdir -p ${FEATURES_DIR}

    # Configure the instance ID
    # Required when having multiple OpenNMS backends sharing the same Kafka cluster.
    if [[ ${INSTANCE_ID} ]]; then
      echo "Configuring Instance ID..."
      cat <<EOF >> ${CUSTOM_PROPERTIES}
    # Used for Kafka Topics
    org.opennms.instance.id=${INSTANCE_ID}
    EOF
    fi

    # Append the same relaxed SNMP4J options that OpenNMS has,
    # to make sure that broken SNMP devices still work with Minions.
    cat <<EOF >> ${CUSTOM_PROPERTIES}
    # SNMP4J Options
    snmp4j.LogFactory=org.snmp4j.log.Log4jLogFactory
    org.snmp4j.smisyntaxes=opennms-snmp4j-smisyntaxes.properties
    org.opennms.snmp.snmp4j.allowSNMPv2InV1=false
    org.opennms.snmp.snmp4j.forwardRuntimeExceptions=false
    org.opennms.snmp.snmp4j.noGetBulk=false
    org.opennms.snmp.workarounds.allow64BitIpAddress=true
    org.opennms.snmp.workarounds.allowZeroLengthIpAddress=true
    EOF

    DNS_LOOKUPS_ENABLED=${DNS_LOOKUPS_ENABLED-false}
    DNS_SERVERS=${DNS_SERVERS-8.8.8.8}
    if [[ ${DNS_LOOKUPS_ENABLED} == "true" ]]; then
      echo "Configuring DNS resolver..."
      cat <<EOF > ${OVERLAY}/org.opennms.features.dnsresolver.netty.cfg
    num-contexts=16
    nameservers=${DNS_SERVERS}
    query-timeout-millis=500
    max-cache-size=500000
    min-ttl-seconds=60
    max-ttl-seconds=300
    negative-ttl-seconds=300
    breaker-enabled=true
    breaker-failure-rate-threshold=90
    breaker-wait-duration-in-open-state=5
    breaker-ring-buffer-size-in-half-open-state=100
    breaker-ring-buffer-size-in-closed-state=50000
    bulkhead-max-concurrent-calls=50000
    bulkhead-max-wait-duration-millis=0
    EOF
    fi

    # Enable tracing with jaeger
    if [[ $JAEGER_AGENT_HOST ]]; then
      cat <<EOF >> ${CUSTOM_PROPERTIES}
    # Enable Tracing
    JAEGER_AGENT_HOST=${JAEGER_AGENT_HOST}
    EOF
      echo "opennms-core-tracing-jaeger" > $FEATURES_DIR/jaeger.boot
    fi

    # Configure Sink and RPC to use Kafka
    if [[ ${KAFKA_SERVER} ]]; then
      echo "Configuring Kafka..."

      if [[ ${KAFKA_SASL_USERNAME} && ${KAFKA_SASL_PASSWORD} ]]; then
        read -r -d '' KAFKA_SASL <<EOF
    security.protocol=SASL_PLAINTEXT
    sasl.mechanism=PLAIN
    sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username="${KAFKA_SASL_USERNAME}" password="${KAFKA_SASL_PASSWORD}";
    EOF
      fi

      cat <<EOF > ${OVERLAY}/org.opennms.core.ipc.sink.kafka.cfg
    bootstrap.servers=${KAFKA_SERVER}:9092
    ${KAFKA_SASL}

    # Producer (verify Kafka broker configuration)
    max.request.size=${KAFKA_MAX_MESSAGE_SIZE}
    acks=1
    linger.ms=5
    compression.type=zstd
    EOF

      cat <<EOF > ${OVERLAY}/org.opennms.core.ipc.rpc.kafka.cfg
    bootstrap.servers=${KAFKA_SERVER}:9092
    request.timeout.ms=30000
    single-topic=true
    max.concurrent.calls=10000
    ${KAFKA_SASL}

    # Consumer (verify Kafka broker configuration)
    max.partition.fetch.bytes=${KAFKA_MAX_MESSAGE_SIZE}
    auto.offset.reset=latest

    # Producer (verify Kafka broker configuration)
    max.request.size=${KAFKA_MAX_MESSAGE_SIZE}
    acks=0
    linger.ms=5
    compression.type=zstd
    EOF

      cat <<EOF > ${FEATURES_DIR}/kafka.boot
    !minion-jms
    !opennms-core-ipc-sink-camel
    !opennms-core-ipc-rpc-jms
    opennms-core-ipc-sink-kafka
    opennms-core-ipc-rpc-kafka
    EOF
    fi

    # Configure SNMP Trap reception
    # Port 162 cannot be used as Minion runs as non-root
    # The queue.size must be consistent with the Kafka message/buffer limits; although on H24+ messages are split.
    cat <<EOF > ${OVERLAY}/org.opennms.netmgt.trapd.cfg
    trapd.listen.interface=0.0.0.0
    trapd.listen.port=1162
    # To control how many traps are included in a single message sent to Kafka
    trapd.batch.size=1000
    # To limit how many messages are kept in memory if Kafka is unreachable
    trapd.queue.size=10000
    EOF

    # Configure Syslog reception
    # Port 514 cannot be used as Minion runs as non-root
    # The queue.size must be consistent with the Kafka message/buffer limits; although on H24+ messages are split.
    cat <<EOF > ${OVERLAY}/org.opennms.netmgt.syslog.cfg
    syslog.listen.interface=0.0.0.0
    syslog.listen.port=1514
    # To control how many syslog messages are included in a single package sent to Kafka
    syslog.batch.size=1000
    # To limit how many syslog messages are kept in memory if Kafka is unreachable
    syslog.queue.size=10000
    EOF

    # Off-heap feature (must be consistent with the memory limits on the Pod)
    cat <<EOF > ${OVERLAY}/org.opennms.core.ipc.sink.offheap.cfg
    offHeapFilePath=
    offHeapSize=512MB
    # How many entries to batch in memory before writing to disk
    batchSize=100
    # Must be a multiple of the batch size
    entriesAllowedOnHeap=100000
    EOF

    ### Optional Settings, only relevant for processing Flows and Telemetry data

    if [[ ${SINGLE_PORT} != "" ]]; then
      echo "Configuring listeners for Horizon on port ${SINGLE_PORT}"

      cat <<EOF > ${OVERLAY}/org.opennms.features.telemetry.listeners-udp-"${SINGLE_PORT}".cfg
    name=Single-Port-Listener
    class-name=org.opennms.netmgt.telemetry.listeners.UdpListener
    parameters.host=0.0.0.0
    parameters.port=${SINGLE_PORT}
    parameters.maxPacketSize=16192
    parsers.0.name=NXOS
    parsers.0.class-name=org.opennms.netmgt.telemetry.protocols.common.parser.ForwardParser
    parsers.0.queue.use-routing-key=true
    parsers.1.name=Netflow-5
    parsers.1.class-name=org.opennms.netmgt.telemetry.protocols.netflow.parser.Netflow5UdpParser
    parsers.1.parameters.dnsLookupsEnabled=${DNS_LOOKUPS_ENABLED}
    parsers.1.parameters.maxClockSkew=300
    parsers.1.queue.use-routing-key=true
    parsers.2.name=Netflow-9
    parsers.2.class-name=org.opennms.netmgt.telemetry.protocols.netflow.parser.Netflow9UdpParser
    parsers.2.parameters.dnsLookupsEnabled=${DNS_LOOKUPS_ENABLED}
    parsers.2.parameters.maxClockSkew=300
    parsers.2.queue.use-routing-key=true
    parsers.3.name=IPFIX
    parsers.3.class-name=org.opennms.netmgt.telemetry.protocols.netflow.parser.IpfixUdpParser
    parsers.3.parameters.dnsLookupsEnabled=${DNS_LOOKUPS_ENABLED}
    parsers.3.parameters.maxClockSkew=300
    parsers.3.queue.use-routing-key=true
    parsers.4.name=SFlow
    parsers.4.class-name=org.opennms.netmgt.telemetry.protocols.sflow.parser.SFlowUdpParser
    parsers.4.parameters.dnsLookupsEnabled=${DNS_LOOKUPS_ENABLED}
    parsers.4.queue.use-routing-key=true
    EOF

    else

      echo "Configuring listeners on default ports"

      cat <<EOF > ${OVERLAY}/org.opennms.features.telemetry.listeners-udp-2003.cfg
    name=Graphite-Listener
    class-name=org.opennms.netmgt.telemetry.listeners.UdpListener
    parameters.host=0.0.0.0
    parameters.port=2003
    parameters.maxPacketSize=16192
    parsers.0.name=Graphite
    parsers.0.class-name=org.opennms.netmgt.telemetry.protocols.common.parser.ForwardParser
    EOF

      cat <<EOF > ${OVERLAY}/org.opennms.features.telemetry.listeners-udp-50001.cfg
    name=NXOS-Listener
    class-name=org.opennms.netmgt.telemetry.listeners.UdpListener
    parameters.host=0.0.0.0
    parameters.port=50001
    parameters.maxPacketSize=16192
    parsers.0.name=NXOS
    parsers.0.class-name=org.opennms.netmgt.telemetry.protocols.common.parser.ForwardParser
    EOF

      cat <<EOF > ${OVERLAY}/org.opennms.features.telemetry.listeners-udp-8877.cfg
    name=Netflow-5-Listener
    class-name=org.opennms.netmgt.telemetry.listeners.UdpListener
    parameters.host=0.0.0.0
    parameters.port=8877
    parameters.maxPacketSize=16192
    parsers.0.name=Netflow-5
    parsers.0.class-name=org.opennms.netmgt.telemetry.protocols.netflow.parser.Netflow5UdpParser
    parsers.0.parameters.dnsLookupsEnabled=${DNS_LOOKUPS_ENABLED}
    parsers.0.parameters.maxClockSkew=300
    EOF

      cat <<EOF > ${OVERLAY}/org.opennms.features.telemetry.listeners-udp-4729.cfg
    name=Netflow-9-Listener
    class-name=org.opennms.netmgt.telemetry.listeners.UdpListener
    parameters.host=0.0.0.0
    parameters.port=4729
    parameters.maxPacketSize=16192
    parsers.0.name=Netflow-9
    parsers.0.class-name=org.opennms.netmgt.telemetry.protocols.netflow.parser.Netflow9UdpParser
    parsers.0.parameters.dnsLookupsEnabled=${DNS_LOOKUPS_ENABLED}
    parsers.0.parameters.maxClockSkew=300
    EOF

      cat <<EOF > ${OVERLAY}/org.opennms.features.telemetry.listeners-udp-6343.cfg
    name=SFlow-Listener
    class-name=org.opennms.netmgt.telemetry.listeners.UdpListener
    parameters.host=0.0.0.0
    parameters.port=6343
    parameters.maxPacketSize=16192
    parsers.0.name=SFlow
    parsers.0.class-name=org.opennms.netmgt.telemetry.protocols.sflow.parser.SFlowUdpParser
    parsers.0.parameters.dnsLookupsEnabled=${DNS_LOOKUPS_ENABLED}
    EOF

      cat <<EOF > ${OVERLAY}/org.opennms.features.telemetry.listeners-udp-4738.cfg
    name=IPFIX-Listener
    class-name=org.opennms.netmgt.telemetry.listeners.UdpListener
    parameters.host=0.0.0.0
    parameters.port=4738
    parameters.maxPacketSize=16192
    parsers.0.name=IPFIX
    parsers.0.class-name=org.opennms.netmgt.telemetry.protocols.netflow.parser.IpfixUdpParser
    parsers.0.parameters.dnsLookupsEnabled=${DNS_LOOKUPS_ENABLED}
    parsers.0.parameters.maxClockSkew=300
    EOF
    fi

    cat <<EOF > ${OVERLAY}/org.opennms.features.telemetry.listeners-bmp-11019.cfg
    name=BMP
    class-name=org.opennms.netmgt.telemetry.listeners.TcpListener
    parameters.host=0.0.0.0
    parameters.port=11019
    parsers.0.name=BMP
    parsers.0.class-name=org.opennms.netmgt.telemetry.protocols.bmp.parser.BmpParser
    EOF
  onms-nephron-init.sh: |
    #!/bin/sh
    # @author Alejandro Galue <agalue@opennms.org>
    #
    # Purpose:
    # - Generate the client settings for Kafka
    #
    # Environment variables:
    # - KAFKA_SASL_USERNAME
    # - KAFKA_SASL_PASSWORD

    cat <<EOF > /data/client.properties
    security.protocol=SASL_PLAINTEXT
    sasl.mechanism=PLAIN
    sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username="${KAFKA_SASL_USERNAME}" password="${KAFKA_SASL_PASSWORD}";
    EOF
  onms-sentinel-init.sh: "#!/bin/bash\n# @author Alejandro Galue <agalue@opennms.org>\n#\n#
    Sentinel is required only for bmp, flows, and streaming telemetry processing.\n#\n#
    Requirements:\n# - Horizon 27 or newer is required\n# - Overlay volume mounted
    at /etc-overlay\n# - NUM_LISTENER_THREADS (i.e. queue.threads) must be consistent
    with the amount of partitions on Kafka\n#\n# Purpose:\n# - Configure instance
    ID.\n# - Configure Telemetry adapters only if Elasticsearch is provided.\n# -
    Configure the Kafka consumers only if Kafka is provided.\n# - Configure the Telemetry
    persistence only if Cassandra is provided.\n#\n# Environment variables:\n# - INSTANCE_ID\n#
    - ELASTIC_SERVER\n# - ELASTIC_PASSWORD\n# - ELASTIC_INDEX_STRATEGY_FLOWS\n# -
    ELASTIC_REPLICATION_FACTOR\n# - ELASTIC_NUM_SHARDS\n# - KAFKA_SERVER\n# - KAFKA_SASL_USERNAME\n#
    - KAFKA_SASL_PASSWORD\n# - CASSANDRA_SERVER\n# - NUM_LISTENER_THREADS\n# - JAEGER_AGENT_HOST\n#
    - USE_NEPHRON\n\n# To avoid issues with OpenShift\numask 002\n\nNUM_LISTENER_THREADS=${NUM_LISTENER_THREADS-6}\nELASTIC_INDEX_STRATEGY_FLOWS=${ELASTIC_INDEX_STRATEGY_FLOWS-daily}\nELASTIC_REPLICATION_FACTOR=${ELASTIC_REPLICATION_FACTOR-2}\nELASTIC_NUM_SHARDS=${ELASTIC_NUM_SHARDS-6}\nUSE_NEPHRON=${USE_NEPHRON-false}\n\nOVERLAY=/etc-overlay\nSENTINEL_HOME=/opt/sentinel\nKEYSPACE=$(echo
    ${INSTANCE_ID-onms}_newts | tr '[:upper:]' '[:lower:]')\n\n# Configure the instance
    ID\n# Required when having multiple OpenNMS backends sharing the same Kafka cluster.\nCUSTOM_PROPERTIES=${OVERLAY}/custom.system.properties\nif
    [[ ${INSTANCE_ID} ]]; then\n  echo \"Configuring Instance ID...\"\n  cat <<EOF
    >> ${CUSTOM_PROPERTIES}\n# Used for Kafka Topics\norg.opennms.instance.id=${INSTANCE_ID}\n#
    Refresh Interface-to-Node cache every 2 hours\norg.opennms.interface-node-cache.refresh-timer=7200000\nEOF\nelse\n
    \ INSTANCE_ID=\"OpenNMS\"\nfi\n\nFEATURES_DIR=${OVERLAY}/featuresBoot.d\nmkdir
    -p ${FEATURES_DIR}\ncat <<EOF > ${FEATURES_DIR}/persistence.boot\nsentinel-persistence\nsentinel-jsonstore-postgres\nEOF\n\n#
    Enable tracing with jaeger\nif [[ ${JAEGER_AGENT_HOST} ]]; then\n  cat <<EOF >>
    ${CUSTOM_PROPERTIES}\n# Enable Tracing\nJAEGER_AGENT_HOST=${JAEGER_AGENT_HOST}\nEOF\n
    \ echo \"opennms-core-tracing-jaeger\" > ${FEATURES_DIR}/jaeger.boot\nfi\n\n#
    Enable BMP\ncat <<EOF > ${FEATURES_DIR}/bmp.boot\nsentinel-telemetry-bmp\nEOF\ncat
    <<EOF > ${OVERLAY}/org.opennms.features.telemetry.adapters-bmp.cfg\nname=BMP\nadapters.0.name=BMP-PeerStatus-Adapter\nadapters.0.class-name=org.opennms.netmgt.telemetry.protocols.bmp.adapter.BmpPeerStatusAdapter\nEOF\nnext_bmp_adapter=1\n\nif
    [[ ${ELASTIC_SERVER} ]]; then\n  echo \"Configuring Elasticsearch...\"\n\n  cat
    <<EOF > ${FEATURES_DIR}/flows.boot\nsentinel-flows\nEOF\n\n  if [[ ! ${CASSANDRA_SERVER}
    ]]; then\n    cat <<EOF > ${OVERLAY}/org.opennms.features.telemetry.adapters-sflow.cfg\nname=SFlow\nadapters.0.name=SFlow-Adapter\nadapters.0.class-name=org.opennms.netmgt.telemetry.protocols.sflow.adapter.SFlowAdapter\nqueue.threads=${NUM_LISTENER_THREADS}\nEOF\n
    \ fi\n\n  cat <<EOF > ${OVERLAY}/org.opennms.features.telemetry.adapters-ipfix.cfg\nname=IPFIX\nadapters.0.name=IPFIX-Adapter\nadapters.0.class-name=org.opennms.netmgt.telemetry.protocols.netflow.adapter.ipfix.IpfixAdapter\nqueue.threads=${NUM_LISTENER_THREADS}\nEOF\n\n
    \ cat <<EOF > ${OVERLAY}/org.opennms.features.telemetry.adapters-netflow5.cfg\nname=Netflow-5\nadapters.0.name=Netflow-5-Adapter\nadapters.0.class-name=org.opennms.netmgt.telemetry.protocols.netflow.adapter.netflow5.Netflow5Adapter\nqueue.threads=${NUM_LISTENER_THREADS}\nEOF\n\n
    \ cat <<EOF > ${OVERLAY}/org.opennms.features.telemetry.adapters-netflow9.cfg\nname=Netflow-9\nadapters.0.name=Netflow-9-Adapter\nadapters.0.class-name=org.opennms.netmgt.telemetry.protocols.netflow.adapter.netflow9.Netflow9Adapter\nqueue.threads=${NUM_LISTENER_THREADS}\nEOF\n\n
    \ PREFIX=$(echo ${INSTANCE_ID} | tr '[:upper:]' '[:lower:]')-\n  cat <<EOF > ${OVERLAY}/org.opennms.features.flows.persistence.elastic.cfg\nelasticUrl=http://${ELASTIC_SERVER}:9200\nglobalElasticUser=elastic\nindexPrefix=${PREFIX}\nglobalElasticPassword=${ELASTIC_PASSWORD}\nelasticIndexStrategy=${ELASTIC_INDEX_STRATEGY_FLOWS}\nclockSkewCorrectionThreshold=5000\nnodeDiscovery=true\nnodeDiscoveryFrequency=3600\n#
    The following settings should be consistent with your ES cluster\nsettings.index.number_of_shards=${ELASTIC_NUM_SHARDS}\nsettings.index.number_of_replicas=${ELASTIC_REPLICATION_FACTOR}\nEOF\n\n
    \ if [[ ${USE_NEPHRON} == \"true\" ]]; then\n    curl https://raw.githubusercontent.com/OpenNMS/nephron/master/main/src/main/resources/netflow_agg-template.json\n
    \   curl -XPUT -H 'Content-Type: application/json' http://${ELASTIC_SERVER}:9200/_template/netflow_agg
    -d@netflow_agg-template.json\n    cat <<EOF >> ${OVERLAY}/org.opennms.features.flows.persistence.elastic.cfg\nenableForwarding=true\nEOF\n
    \ fi\nfi\n\nif [[ ${KAFKA_SERVER} ]]; then\n  echo \"Configuring Kafka...\"\n\n
    \ if [[ ${KAFKA_SASL_USERNAME} && ${KAFKA_SASL_PASSWORD} ]]; then\n    read -r
    -d '' KAFKA_SASL <<EOF\nsecurity.protocol=SASL_PLAINTEXT\nsasl.mechanism=PLAIN\nsasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule
    required username=\"${KAFKA_SASL_USERNAME}\" password=\"${KAFKA_SASL_PASSWORD}\";\nEOF\n
    \ fi\n\n  echo \"sentinel-kafka\" > ${FEATURES_DIR}/kafka.boot\n\n  cat <<EOF
    > ${OVERLAY}/org.opennms.core.ipc.sink.kafka.cfg\n# Producers\nbootstrap.servers=${KAFKA_SERVER}:9092\nacks=1\n${KAFKA_SASL}\nEOF\n\n
    \ cat <<EOF > ${OVERLAY}/org.opennms.core.ipc.sink.kafka.consumer.cfg\n# Consumers\ngroup.id=${INSTANCE_ID}_Sentinel\nbootstrap.servers=${KAFKA_SERVER}:9092\nmax.partition.fetch.bytes=5000000\n${KAFKA_SASL}\nEOF\n\n
    \ next_bmp_adapter=$((next_bmp_adapter+1))\n  cat <<EOF >> ${OVERLAY}/org.opennms.features.telemetry.adapters-bmp.cfg\nadapters.$next_bmp_adapter.name=BMP-OpenBMP-Integration-Adapter\nadapters.$next_bmp_adapter.class-name=org.opennms.netmgt.telemetry.protocols.bmp.adapter.openbmp.BmpIntegrationAdapter\nadapters.$next_bmp_adapter.parameters.kafka.bootstrap.servers=${KAFKA_SERVER}:9092\nadapters.$next_bmp_adapter.parameters.kafka.security.protocol=SASL_PLAINTEXT\nadapters.$next_bmp_adapter.parameters.kafka.sasl.mechanism=PLAIN\nadapters.$next_bmp_adapter.parameters.kafka.sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule
    required username=\"${KAFKA_SASL_USERNAME}\" password=\"${KAFKA_SASL_PASSWORD}\";\nEOF\n\n\n
    \ if [[ ${USE_NEPHRON} == \"true\" ]]; then\n    cat <<EOF > ${OVERLAY}/org.opennms.features.flows.persistence.kafka.cfg\ntopic=${INSTANCE_ID}_opennms_flows\nbootstrap.servers=${KAFKA_SERVER}:9092\n${KAFKA_SASL}\nEOF\n
    \ fi\nfi\n\nif [[ ${CASSANDRA_SERVER} ]]; then\n  echo \"Configuring Cassandra...\"\n\n
    \ cat <<EOF > ${FEATURES_DIR}/telemetry.boot\nsentinel-newts\nsentinel-telemetry-nxos\nsentinel-telemetry-jti\nsentinel-telemetry-graphite\nsentinel-blobstore-cassandra\nEOF\n\n
    \ cat <<EOF >> ${CUSTOM_PROPERTIES}\n# WARNING: Must match OpenNMS in order to
    properly store telemetry metrics on Cassandra\norg.opennms.rrd.storeByGroup=true\norg.opennms.rrd.storeByForeignSource=true\nEOF\n\n
    \ cat <<EOF > ${OVERLAY}/org.opennms.newts.config.cfg\n# About the properties:\n#
    - Must match what OpenNMS has configured for Newts\n# - ring_buffer_size and cache.max_entries
    should be consistent with the expected load and heap size\n\nhostname=${CASSANDRA_SERVER}\nkeyspace=${KEYSPACE}\nport=9042\nread_consistency=ONE\nwrite_consistency=ANY\nresource_shard=604800\nttl=31540000\ncache.strategy=org.opennms.netmgt.newts.support.GuavaSearchableResourceMetadataCache\nring_buffer_size=131072\ncache.max_entries=131072\nEOF\n\n
    \ cat <<EOF > ${OVERLAY}/org.opennms.features.telemetry.adapters-sflow-telemetry.cfg\nname=SFlow\nadapters.1.name=SFlow-Adapter\nadapters.1.class-name=org.opennms.netmgt.telemetry.protocols.sflow.adapter.SFlowAdapter\nadapters.2.name=SFlow-Telemetry\nadapters.2.class-name=org.opennms.netmgt.telemetry.protocols.sflow.adapter.SFlowTelemetryAdapter\nadapters.2.parameters.script=${SENTINEL_HOME}/etc/sflow-host.groovy\nqueue.threads=${NUM_LISTENER_THREADS}\nEOF\n\n
    \ cat <<EOF > ${OVERLAY}/org.opennms.features.telemetry.adapters-nxos.cfg\nname=NXOS\nadapters.0.name=NXOS-Adapter\nadapters.0.class-name=org.opennms.netmgt.telemetry.protocols.nxos.adapter.NxosGpbAdapter\nadapters.0.parameters.script=${SENTINEL_HOME}/etc/cisco-nxos-telemetry-interface.groovy\nqueue.threads=${NUM_LISTENER_THREADS}\nEOF\n\n
    \ cat <<EOF > ${OVERLAY}/org.opennms.features.telemetry.adapters-jti.cfg\nname=JTI\nadapters.0.name=JTI-Adapter\nadapters.0.class-name=org.opennms.netmgt.telemetry.protocols.jti.adapter.JtiGpbAdapter\nadapters.0.parameters.script=${SENTINEL_HOME}/etc/junos-telemetry-interface.groovy\nqueue.threads=${NUM_LISTENER_THREADS}\nEOF\n\n
    \ cat <<EOF > ${OVERLAY}/org.opennms.features.telemetry.adapters-graphite.cfg\nname=Graphite\nadapters.0.name=Graphite-Adapter\nadapters.0.class-name=org.opennms.netmgt.telemetry.protocols.graphite.adapter.GraphiteAdapter\nadapters.0.parameters.script=${SENTINEL_HOME}/etc/graphite-telemetry-interface.groovy\nEOF\n\n
    \ next_bmp_adapter=$((next_bmp_adapter+1))\n  cat <<EOF >> ${OVERLAY}/org.opennms.features.telemetry.adapters-bmp.cfg\nadapters.$next_bmp_adapter.name=BMP-Telemetry-Adapter\nadapters.$next_bmp_adapter.class-name=org.opennms.netmgt.telemetry.protocols.bmp.adapter.BmpTelemetryAdapter\nEOF\n\n
    \ next_bmp_adapter=$((next_bmp_adapter+1))\n  cat <<EOF >> ${OVERLAY}/org.opennms.features.telemetry.adapters-bmp.cfg\nadapters.$next_bmp_adapter.name=BMP-Persisting-Adapter\nadapters.$next_bmp_adapter.class-name=org.opennms.netmgt.telemetry.protocols.bmp.adapter.BmpPersistingAdapter\nEOF\n\n
    \ cat <<EOF > ${OVERLAY}/datacollection-config.xml\n<datacollection-config xmlns=\"http://xmlns.opennms.org/xsd/config/datacollection\"
    rrdRepository=\"/var/opennms/rrd/snmp/\">\n  <snmp-collection name=\"default\"
    snmpStorageFlag=\"select\">\n    <rrd step=\"300\">\n      <rra>RRA:AVERAGE:0.5:1:2016</rra>\n
    \     <rra>RRA:AVERAGE:0.5:12:1488</rra>\n      <rra>RRA:AVERAGE:0.5:288:366</rra>\n
    \     <rra>RRA:MAX:0.5:288:366</rra>\n      <rra>RRA:MIN:0.5:288:366</rra>\n    </rrd>\n
    \   <include-collection dataCollectionGroup=\"MIB2\"/>\n  </snmp-collection>\n</datacollection-config>\nEOF\n\n
    \ mkdir -p ${OVERLAY}/resource-types.d\n  cat <<EOF > ${OVERLAY}/resource-types.d/nxos-resources.xml\n<?xml
    version=\"1.0\"?>\n<resource-types>\n  <resourceType name=\"nxosCpu\" label=\"Nxos
    Cpu\" resourceLabel=\"\\${index}\">\n    <persistenceSelectorStrategy class=\"org.opennms.netmgt.collection.support.PersistAllSelectorStrategy\"/>\n
    \   <storageStrategy class=\"org.opennms.netmgt.collection.support.IndexStorageStrategy\"/>\n
    \ </resourceType>\n  <resourceType name=\"nxosIntf\" label=\"Nxos Interface\"
    resourceLabel=\"\\${index}\">\n    <persistenceSelectorStrategy class=\"org.opennms.netmgt.collection.support.PersistAllSelectorStrategy\"/>\n
    \   <storageStrategy class=\"org.opennms.netmgt.collection.support.IndexStorageStrategy\"/>\n
    \ </resourceType>\n</resource-types>\nEOF\n\n  mkdir -p ${OVERLAY}/datacollection\n
    \ cat <<EOF > ${OVERLAY}/datacollection/mib2.xml\n<datacollection-group xmlns=\"http://xmlns.opennms.org/xsd/config/datacollection\"
    name=\"MIB2\">\n  <group name=\"mib2-X-interfaces\" ifType=\"all\">\n    <mibObj
    oid=\".1.3.6.1.2.1.31.1.1.1.1\" instance=\"ifIndex\" alias=\"ifName\" type=\"string\"/>\n
    \   <mibObj oid=\".1.3.6.1.2.1.31.1.1.1.15\" instance=\"ifIndex\" alias=\"ifHighSpeed\"
    type=\"string\"/>\n    <mibObj oid=\".1.3.6.1.2.1.31.1.1.1.6\" instance=\"ifIndex\"
    alias=\"ifHCInOctets\" type=\"Counter64\"/>\n    <mibObj oid=\".1.3.6.1.2.1.31.1.1.1.10\"
    instance=\"ifIndex\" alias=\"ifHCOutOctets\" type=\"Counter64\"/>\n  </group>\n
    \ <systemDef name=\"Enterprise\">\n    <sysoidMask>.1.3.6.1.4.1.</sysoidMask>\n
    \   <collect>\n      <includeGroup>mib2-X-interfaces</includeGroup>\n    </collect>\n
    \ </systemDef>\n</datacollection-group>\nEOF\n\n  cat <<EOF > ${OVERLAY}/sflow-host.groovy\nimport
    static org.opennms.netmgt.telemetry.protocols.common.utils.BsonUtils.get\nimport
    static org.opennms.netmgt.telemetry.protocols.common.utils.BsonUtils.getDouble\nimport
    static org.opennms.netmgt.telemetry.protocols.common.utils.BsonUtils.getInt64\nimport
    org.opennms.netmgt.collection.support.builder.NodeLevelResource\n\nNodeLevelResource
    nodeLevelResource = new NodeLevelResource(agent.getNodeId())\n\nget(msg, \"counters\",
    \"0:2003\").ifPresent { doc ->\n  builder.withGauge(nodeLevelResource, \"host-cpu\",
    \"load_avg_1min\", getDouble(doc, \"load_one\").get())\n  builder.withGauge(nodeLevelResource,
    \"host-cpu\", \"load_avg_5min\", getDouble(doc, \"load_five\").get())\n  builder.withGauge(nodeLevelResource,
    \"host-cpu\", \"load_avg_15min\", getDouble(doc, \"load_fifteen\").get())\n}\n\nget(msg,
    \"counters\", \"0:2004\").ifPresent { doc ->\n  builder.withGauge(nodeLevelResource,
    \"host-memory\", \"mem_total\", getInt64(doc, \"mem_total\").get())\n  builder.withGauge(nodeLevelResource,
    \"host-memory\", \"mem_free\", getInt64(doc, \"mem_free\").get())\n  builder.withGauge(nodeLevelResource,
    \"host-memory\", \"mem_shared\", getInt64(doc, \"mem_shared\").get())\n  builder.withGauge(nodeLevelResource,
    \"host-memory\", \"mem_buffers\", getInt64(doc, \"mem_buffers\").get())\n  builder.withGauge(nodeLevelResource,
    \"host-memory\", \"mem_cached\", getInt64(doc, \"mem_cached\").get())\n}\nEOF\n\n
    \ cat <<EOF > ${OVERLAY}/junos-telemetry-interface.groovy\nimport org.opennms.netmgt.telemetry.protocols.jti.adapter.proto.Port\nimport
    org.opennms.netmgt.telemetry.protocols.jti.adapter.proto.TelemetryTop\nimport
    groovy.util.logging.Slf4j\nimport org.opennms.core.utils.RrdLabelUtils\nimport
    org.opennms.netmgt.collection.api.AttributeType\nimport org.opennms.netmgt.collection.support.builder.InterfaceLevelResource\nimport
    org.opennms.netmgt.collection.support.builder.NodeLevelResource\n\n@Slf4j\nclass
    CollectionSetGenerator {\n  static generate(agent, builder, jtiMsg) {\n    log.debug(\"Generating
    collection set for message: {}\", jtiMsg)\n    NodeLevelResource nodeLevelResource
    = new NodeLevelResource(agent.getNodeId())\n    TelemetryTop.EnterpriseSensors
    entSensors = jtiMsg.getEnterprise()\n    TelemetryTop.JuniperNetworksSensors jnprSensors
    = entSensors.getExtension(TelemetryTop.juniperNetworks);\n    Port.GPort port
    = jnprSensors.getExtension(Port.jnprInterfaceExt);\n    for (Port.InterfaceInfos
    interfaceInfos : port.getInterfaceStatsList()) {\n      String interfaceLabel
    = RrdLabelUtils.computeLabelForRRD(interfaceInfos.getIfName(), null, null);\n
    \     InterfaceLevelResource interfaceResource = new InterfaceLevelResource(nodeLevelResource,
    interfaceLabel);\n      builder.withNumericAttribute(interfaceResource, \"mib2-interfaces\",
    \"ifInOctets\", interfaceInfos.getIngressStats().getIfOctets(), AttributeType.COUNTER);\n
    \     builder.withNumericAttribute(interfaceResource, \"mib2-interfaces\", \"ifOutOctets\",
    interfaceInfos.getEgressStats().getIfOctets(), AttributeType.COUNTER);\n    }\n
    \ }\n}\n\nTelemetryTop.TelemetryStream jtiMsg = msg\nCollectionSetGenerator.generate(agent,
    builder, jtiMsg)\nEOF\n\n  cat <<EOF > ${OVERLAY}/cisco-nxos-telemetry-interface.groovy\nimport
    org.opennms.netmgt.telemetry.protocols.nxos.adapter.proto.TelemetryBis\nimport
    org.opennms.netmgt.telemetry.protocols.nxos.adapter.NxosGpbParserUtil\nimport
    groovy.util.logging.Slf4j\nimport java.util.List\nimport java.util.Objects\nimport
    org.opennms.netmgt.collection.api.AttributeType\nimport org.opennms.netmgt.collection.support.builder.DeferredGenericTypeResource\nimport
    org.opennms.netmgt.collection.support.builder.NodeLevelResource\n\n@Slf4j\nclass
    CollectionSetGenerator {\n  static generate(agent, builder, telemetryMsg) {\n
    \   log.debug(\"Generating collection set for node {} from message: {}\", agent.getNodeId(),
    telemetryMsg)\n\n    def nodeLevelResource = new NodeLevelResource(agent.getNodeId())\n
    \   if (telemetryMsg.getEncodingPath().equals(\"show system resources\")) {\n
    \     builder.withNumericAttribute(nodeLevelResource, \"nxos-stats\", \"load_avg_1min\",\n
    \       NxosGpbParserUtil.getValueAsDouble(telemetryMsg, \"load_avg_1min\"), AttributeType.GAUGE)\n
    \     builder.withNumericAttribute(nodeLevelResource, \"nxos-stats\", \"memory_usage_used\",\n
    \       NxosGpbParserUtil.getValueAsDouble(telemetryMsg, \"memory_usage_used\"),
    AttributeType.GAUGE)\n      NxosGpbParserUtil.getRowsFromTable(telemetryMsg, \"cpu_usage\").each
    { row ->\n        def cpuId = NxosGpbParserUtil.getValueFromRowAsString(row, \"cpuid\")\n
    \       def genericTypeResource = new DeferredGenericTypeResource(nodeLevelResource,
    \"nxosCpu\", cpuId)\n        [\"idle\", \"kernel\", \"user\"].each { metric ->\n
    \         builder.withNumericAttribute(genericTypeResource, \"nxos-cpu-stats\",
    metric,\n            NxosGpbParserUtil.getValueFromRowAsDouble(row, metric), AttributeType.GAUGE)\n
    \       }\n      }\n    }\n\n    // Requires gRPC, this won't work with UDP\n
    \   if (telemetryMsg.getEncodingPath().equals(\"sys/intf\")) {\n      findFieldWithName(telemetryMsg.getDataGpbkvList().get(0),
    \"children\").getFieldsList()\n        .each { f ->\n          def intfId = findFieldWithName(f,
    \"id\").getStringValue().replaceAll(/\\\\//,\"_\")\n          log.debug(\"Processing
    NX-OS interface {}\", intfId)\n          def genericTypeResource = new DeferredGenericTypeResource(nodeLevelResource,
    \"nxosIntf\", intfId)\n          def rmonIfHCIn = findFieldWithName(f, \"rmonIfHCIn\");\n
    \         def rmonIfHCOut = findFieldWithName(f, \"rmonIfHCOut\");\n          if
    (rmonIfHCIn != null && rmonIfHCOut != null) {\n            [\"ucastPkts\", \"multicastPkts\",
    \"broadcastPkts\", \"octets\"].each { metric ->\n              builder.withNumericAttribute(genericTypeResource,
    \"nxosRmonIntfStats\", \"in\\$metric\",\n                NxosGpbParserUtil.getValueFromRowAsDouble(rmonIfHCIn,
    metric), AttributeType.COUNTER)\n              builder.withNumericAttribute(genericTypeResource,
    \"nxosRmonIntfStats\", \"out\\$metric\",\n                NxosGpbParserUtil.getValueFromRowAsDouble(rmonIfHCOut,
    metric), AttributeType.COUNTER)\n            }\n          }\n        }\n    }
    \n  }\n\n  static findFieldWithName(TelemetryBis.TelemetryField field, String
    name) {\n    if (Objects.equals(field.getName(), name)) {\n      return field\n
    \   }\n    for (subField in field.getFieldsList()) {\n      def matchingField
    = findFieldWithName(subField, name)\n      if (matchingField != null) {\n        return
    matchingField\n      }\n    }\n    return null\n  }\n}\n\nTelemetryBis.Telemetry
    telemetryMsg = msg\nCollectionSetGenerator.generate(agent, builder, telemetryMsg)\nEOF\n\n
    \ cat <<EOF > ${OVERLAY}/graphite-telemetry-interface.groovy\nimport groovy.util.logging.Slf4j\nimport
    org.opennms.core.utils.RrdLabelUtils\nimport org.opennms.netmgt.collection.api.AttributeType\nimport
    org.opennms.netmgt.telemetry.protocols.graphite.adapter.GraphiteMetric\nimport
    org.opennms.netmgt.collection.support.builder.InterfaceLevelResource\nimport org.opennms.netmgt.collection.support.builder.NodeLevelResource\n\n@Slf4j\nclass
    CollectionSetGenerator {\n  static generate(agent, builder, graphiteMsg) {\n    log.debug(\"Generating
    collection set for message: {}\", graphiteMsg)\n    def nodeLevelResource = new
    NodeLevelResource(agent.getNodeId())\n    if (graphiteMsg.path.startsWith(\"eth\"))
    {\n      def ifaceLabel = RrdLabelUtils.computeLabelForRRD(graphiteMsg.path.split(\".\")[0],
    null, null);\n      def interfaceResource = new InterfaceLevelResource(nodeLevelResource,
    interfaceLabel);\n      builder.withGauge(interfaceResource, \"some-group\", graphiteMsg.path.split(\".\")[1],
    graphitMsg.longValue());\n    } else {\n      log.warn(\"Cannot handle message
    from graphite. {}\", graphiteMsg);\n    }\n  }\n}\n\nGraphiteMetric graphiteMsg
    = msg\nCollectionSetGenerator.generate(agent, builder, graphiteMsg)\nEOF\nelse\n
    \ cat <<EOF >> ${FEATURES_DIR}/persistence.boot\nsentinel-blobstore-noop\nEOF\nfi\n"
  onms-ui-init.sh: |
    #!/bin/bash
    # @author Alejandro Galue <agalue@opennms.org>
    #
    # Requirements:
    # - Horizon 27 or newer is required.
    # - Config overlay volume mounted at /opt/opennms-etc-overlay
    # - Webinf overlay volume mounted at /opt/opennms-jetty-webinf-overlay
    # - Must run within a init-container based on the opennms/horizon image.
    #   Version must match the runtime container.
    # - The following commands must be pre-installed on the chosen image:
    #   jq, curl
    #
    # Purpose:
    # - Apply recommended changes to force OpenNMS to be a read-only WebUI server.
    #   Only Eventd, Jetty and Karaf will be running.
    # - Apply mandatory configuration changes based on the provided variables.
    #
    # External Environment variables:
    # - INSTANCE_ID
    # - CASSANDRA_SERVER
    # - ELASTIC_SERVER
    # - ELASTIC_PASSWORD
    # - ELASTIC_INDEX_STRATEGY_FLOWS
    # - GRAFANA_URL
    # - GRAFANA_PUBLIC_URL
    # - GF_SECURITY_ADMIN_PASSWORD

    # To avoid issues with OpenShift
    umask 002

    command -v jq   >/dev/null 2>&1 || { echo >&2 "jq is required but it's not installed. Aborting.";   exit 1; }
    command -v curl >/dev/null 2>&1 || { echo >&2 "curl is required but it's not installed. Aborting."; exit 1; }

    CONFIG_DIR=/opt/opennms-etc-overlay
    WEB_DIR=/opt/opennms-jetty-webinf-overlay
    KEYSPACE=$(echo ${INSTANCE_ID-onms}_newts | tr '[:upper:]' '[:lower:]')

    mkdir -p ${CONFIG_DIR}/opennms.properties.d/
    touch ${CONFIG_DIR}/configured

    # Configure the instance ID
    # Required when having multiple OpenNMS backends sharing the same Kafka cluster.
    if [[ ${INSTANCE_ID} ]]; then
      echo "Configuring Instance ID..."
      cat <<EOF > ${CONFIG_DIR}/opennms.properties.d/instanceid.properties
    # Used for Kafka Topics
    org.opennms.instance.id=${INSTANCE_ID}
    EOF
    else
      INSTANCE_ID="OpenNMS"
    fi

    # Disable data choices (optional)
    cat <<EOF > ${CONFIG_DIR}/org.opennms.features.datachoices.cfg
    enabled=false
    acknowledged-by=admin
    acknowledged-at=Mon Jan 01 00\:00\:00 EDT 2018
    EOF

    # Trim down the events configuration, as event processing is not required for the WebUI
    cat <<EOF > ${CONFIG_DIR}/eventconf.xml
    <?xml version="1.0"?>
    <events xmlns="http://xmlns.opennms.org/xsd/eventconf">
      <global>
        <security>
          <doNotOverride>logmsg</doNotOverride>
          <doNotOverride>operaction</doNotOverride>
          <doNotOverride>autoaction</doNotOverride>
          <doNotOverride>tticket</doNotOverride>
          <doNotOverride>script</doNotOverride>
        </security>
      </global>
    EOF
    grep 'events\/opennms' /opt/opennms/share/etc-pristine/eventconf.xml >> ${CONFIG_DIR}/eventconf.xml
    cat <<EOF >> ${CONFIG_DIR}/eventconf.xml
    </events>
    EOF

    # Trim down the services/daemons configuration, as only the WebUI will be running
    cat <<EOF > ${CONFIG_DIR}/service-configuration.xml
    <?xml version="1.0"?>
    <service-configuration xmlns="http://xmlns.opennms.org/xsd/config/vmmgr">
      <service>
        <name>OpenNMS:Name=Manager</name>
        <class-name>org.opennms.netmgt.vmmgr.Manager</class-name>
        <invoke at="stop" pass="1" method="doSystemExit"/>
      </service>
      <service>
        <name>OpenNMS:Name=TestLoadLibraries</name>
        <class-name>org.opennms.netmgt.vmmgr.Manager</class-name>
        <invoke at="start" pass="0" method="doTestLoadLibraries"/>
      </service>
      <service>
        <name>OpenNMS:Name=Eventd</name>
        <class-name>org.opennms.netmgt.eventd.jmx.Eventd</class-name>
        <invoke at="start" pass="0" method="init"/>
        <invoke at="start" pass="1" method="start"/>
        <invoke at="status" pass="0" method="status"/>
        <invoke at="stop" pass="0" method="stop"/>
      </service>
      <service>
        <name>OpenNMS:Name=JettyServer</name>
        <class-name>org.opennms.netmgt.jetty.jmx.JettyServer</class-name>
        <invoke at="start" pass="0" method="init"/>
        <invoke at="start" pass="1" method="start"/>
        <invoke at="status" pass="0" method="status"/>
        <invoke at="stop" pass="0" method="stop"/>
      </service>
    </service-configuration>
    EOF

    # Required changes in order to use HTTPS through Ingress
    cat <<EOF > ${CONFIG_DIR}/opennms.properties.d/webui.properties
    opennms.web.base-url=https://%x%c/
    opennms.report.scheduler.enabled=false
    org.opennms.security.disableLoginSuccessEvent=true
    org.opennms.web.console.centerUrl=/status/status-box.jsp,/geomap/map-box.jsp,/heatmap/heatmap-box.jsp
    org.opennms.web.defaultGraphPeriod=last_2_hour
    EOF

    # Guard against allowing administration changes through the WebUI
    SECURITY_CONFIG=${WEB_DIR}/applicationContext-spring-security.xml
    cp /opt/opennms/jetty-webapps/opennms/WEB-INF/applicationContext-spring-security.xml ${SECURITY_CONFIG}
    sed -r -i 's/ROLE_ADMIN/ROLE_DISABLED/' ${SECURITY_CONFIG}
    sed -r -i 's/ROLE_PROVISION/ROLE_DISABLED/' ${SECURITY_CONFIG}
    sed -r -i -e '/intercept-url.*measurements/a\' -e '    <intercept-url pattern="/rest/resources/generateId" method="POST" access="ROLE_REST,ROLE_DISABLED,ROLE_USER"/>' ${SECURITY_CONFIG}

    # Enabling CORS
    WEB_CONFIG=${WEB_DIR}/web.xml
    cp /opt/opennms/jetty-webapps/opennms/WEB-INF/web.xml ${WEB_CONFIG}
    sed -r -i '/[<][!]--/{$!{N;s/[<][!]--\n  ([<]filter-mapping)/\1/}}' ${WEB_CONFIG}
    sed -r -i '/nrt/{$!{N;N;s/(nrt.*\n  [<]\/filter-mapping[>])\n  --[>]/\1/}}' ${WEB_CONFIG}

    # Configure Newts (works with either Cassandra or ScyllaDB)
    # This has to match the configuration of the OpenNMS Core server.
    if [[ ${CASSANDRA_SERVER} ]]; then
      echo "Configuring Cassandra..."
      cat <<EOF > ${CONFIG_DIR}/opennms.properties.d/newts.properties
    # Warning:
    # - Make sure the properties match the content of the core OpenNMS server

    org.opennms.rrd.storeByGroup=true
    org.opennms.rrd.storeByForeignSource=true

    org.opennms.timeseries.strategy=newts
    org.opennms.newts.config.hostname=${CASSANDRA_SERVER}
    org.opennms.newts.config.keyspace=${KEYSPACE}
    org.opennms.newts.config.port=9042
    org.opennms.newts.config.read_consistency=ONE
    org.opennms.newts.config.resource_shard=604800
    EOF

      # Required only when collecting data every 30 seconds
      echo "Configuring Optional Newts Settings..."
      cat <<EOF >> ${CONFIG_DIR}/opennms.properties.d/newts.properties
    org.opennms.newts.query.minimum_step=30000
    org.opennms.newts.query.heartbeat=450000
    EOF

    fi

    # Configure Elasticsearch for Flow processing
    if [[ ${ELASTIC_SERVER} ]]; then
      echo "Configuring Elasticsearch for Flows..."
      PREFIX=$(echo ${INSTANCE_ID} | tr '[:upper:]' '[:lower:]')-
      cat <<EOF > ${CONFIG_DIR}/org.opennms.features.flows.persistence.elastic.cfg
    elasticUrl=http://${ELASTIC_SERVER}:9200
    globalElasticUser=elastic
    globalElasticPassword=${ELASTIC_PASSWORD}
    indexPrefix=${PREFIX}
    elasticIndexStrategy=${ELASTIC_INDEX_STRATEGY_FLOWS}
    EOF
    fi

    # Configure NXOS Resource Types
    echo "Configuring NXOS resource types..."
    mkdir -p ${CONFIG_DIR}/resource-types.d/
    cat <<EOF > ${CONFIG_DIR}/resource-types.d/nxos-intf-resources.xml
    <?xml version="1.0"?>
    <resource-types>
      <resourceType name="nxosIntf" label="Nxos Interface" resourceLabel="\${index}">
        <persistenceSelectorStrategy class="org.opennms.netmgt.collection.support.PersistAllSelectorStrategy"/>
        <storageStrategy class="org.opennms.netmgt.collection.support.IndexStorageStrategy"/>
      </resourceType>
    </resource-types>
    EOF

    # Enable Grafana features
    if [[ ${GRAFANA_PUBLIC_URL} ]] && [[ ${GRAFANA_URL} ]] && [[ ${GF_SECURITY_ADMIN_PASSWORD} ]]; then
      GRAFANA_AUTH="admin:${GF_SECURITY_ADMIN_PASSWORD}"
      FLOW_DASHBOARD=$(curl -u "${GRAFANA_AUTH}" "${GRAFANA_URL}/api/search?query=flow" 2>/dev/null | jq '.[0].url' | sed 's/"//g')
      echo "Flow Dashboard: ${FLOW_DASHBOARD}"
      if [ "${FLOW_DASHBOARD}" != "null" ]; then
        cat <<EOF > ${CONFIG_DIR}/org.opennms.netmgt.flows.rest.cfg
    flowGraphUrl=${GRAFANA_PUBLIC_URL}${FLOW_DASHBOARD}?node=\$nodeId&interface=\$ifIndex
    EOF
      else
        echo "WARNING: cannot get Dashboard URL for the Deep Dive Tool"
      fi

      KEY_ID=$(curl -u "${GRAFANA_AUTH}" "${GRAFANA_URL}/api/auth/keys" 2>/dev/null | jq '.[] | select(.name="opennms-ui") | .id')
      if [ "${KEY_ID}" != "" ]; then
        echo "WARNING: API Key exist, deleting it prior re-creating it again"
        curl -XDELETE -u "${GRAFANA_AUTH}" "${GRAFANA_URL}/api/auth/keys/${KEY_ID}" 2>/dev/null
        echo ""
      fi
      GRAFANA_KEY=$(curl -u "${GRAFANA_AUTH}" -X POST -H "Content-Type: application/json" -d '{"name":"opennms-ui", "role": "Viewer"}' "${GRAFANA_URL}/api/auth/keys" 2>/dev/null | jq .key - | sed 's/"//g')
      if [ "${GRAFANA_KEY}" != "null" ]; then
        echo "Configuring Grafana Box..."
        GRAFANA_HOSTNAME=$(echo "${GRAFANA_PUBLIC_URL}" | sed -E 's/http[s]?:|\///g')
        mkdir -p ${CONFIG_DIR}/opennms.properties.d/
        cat <<EOF > ${CONFIG_DIR}/opennms.properties.d/grafana.properties
    org.opennms.grafanaBox.show=true
    org.opennms.grafanaBox.hostname=${GRAFANA_HOSTNAME}
    org.opennms.grafanaBox.port=443
    org.opennms.grafanaBox.basePath=/
    org.opennms.grafanaBox.apiKey=${GRAFANA_KEY}
    EOF
      else
        echo "WARNING: cannot get Grafana Key"
      fi
    fi
kind: ConfigMap
metadata:
  annotations:
    owner: agalue@opennms.org
  labels:
    target: opennms
  name: init-scripts
  namespace: opennms
---
apiVersion: v1
data:
  postgresql.conf: |+
    listen_addresses = '*'
    shared_buffers = 512MB
    max_connections = 300
    effective_cache_size = 1536MB
    maintenance_work_mem = 128MB
    checkpoint_completion_target = 0.9
    wal_buffers = 16MB
    default_statistics_target = 100
    random_page_cost = 1.1
    effective_io_concurrency = 300
    work_mem = 873kB
    min_wal_size = 1GB
    max_wal_size = 2GB
    max_worker_processes = 2
    max_parallel_workers_per_gather = 1
    max_parallel_workers = 2

kind: ConfigMap
metadata:
  labels:
    app: postgresql
  name: postgresql-config
  namespace: opennms
---
apiVersion: v1
data:
  ELASTICSEARCH_PASSWORD: ZWxhc3RpYw==
  ELASTICSEARCH_USERNAME: ZWxhc3RpYw==
  GRAFANA_DB_PASSWORD: Z3JhZmFuYQ==
  GRAFANA_DB_USERNAME: Z3JhZmFuYQ==
  GRAFANA_UI_ADMIN_PASSWORD: MHAzbk5NUw==
  HASURA_GRAPHQL_ACCESS_KEY: MHAzbk5NUw==
  KAFKA_CLIENT_PASSWORD: MHAzbk5NNQ==
  KAFKA_CLIENT_USER: b3Blbm5tcw==
  KAFKA_INTER_BROKER_PASSWORD: S0Bma0A=
  KAFKA_INTER_BROKER_USER: a2Fma2E=
  KAFKA_MANAGER_APPLICATION_SECRET: MHAzbk5NUw==
  KAFKA_MANAGER_PASSWORD: MHAzbk5NUw==
  KAFKA_MANAGER_USERNAME: b3Blbm5tcw==
  OPENNMS_DB_PASSWORD: b3Blbm5tcw==
  OPENNMS_UI_ADMIN_PASSWORD: YWRtaW4=
  POSTGRES_PASSWORD: cG9zdGdyZXM=
kind: Secret
metadata:
  annotations:
    owner: agalue@opennms.org
  labels:
    target: opennms
  name: onms-passwords
  namespace: opennms
type: Opaque
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app: cassandra
  name: cassandra
  namespace: opennms
spec:
  clusterIP: None
  ports:
  - name: intra-node
    port: 7000
  - name: tls-intra-node
    port: 7001
  - name: jmx
    port: 7199
  - name: cql
    port: 9042
  selector:
    app: cassandra
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app: elasticsearch
    role: esdata
  name: esdata
  namespace: opennms
spec:
  clusterIP: None
  ports:
  - name: http
    port: 9200
  - name: transport
    port: 9300
  selector:
    role: esdata
---
apiVersion: v1
kind: Service
metadata:
  name: flink-taskmanager
  namespace: opennms
spec:
  clusterIP: None
  ports:
  - name: data
    port: 6121
  - name: rpc
    port: 6122
  - name: query
    port: 6125
  selector:
    app: flink
    component: taskmanager
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app: grafana
  name: grafana
  namespace: opennms
spec:
  ports:
  - name: http
    port: 3000
  selector:
    app: grafana
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app: grafana-renderer
  name: grafana-renderer
  namespace: opennms
spec:
  ports:
  - name: http
    port: 8081
  selector:
    app: grafana-renderer
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app: grpc-server
  name: grpc-server
  namespace: opennms
spec:
  ports:
  - name: http
    port: 8990
  - name: prometheus
    port: 2112
  selector:
    app: grpc-server
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app: kafka
  name: kafka
  namespace: opennms
spec:
  clusterIP: None
  ports:
  - name: client
    port: 9092
  - name: jmx
    port: 9999
  selector:
    app: kafka
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app: kafka-manager
  name: kafka-manager
  namespace: opennms
spec:
  ports:
  - name: http
    port: 9000
  selector:
    app: kafka-manager
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app: minion
  name: minion
  namespace: opennms
spec:
  clusterIP: None
  ports:
  - name: karaf
    port: 8201
    protocol: TCP
    targetPort: karaf
  - name: http
    port: 8181
    protocol: TCP
    targetPort: http
  - name: traps
    port: 1162
    protocol: UDP
    targetPort: traps
  - name: syslog
    port: 1514
    protocol: UDP
    targetPort: syslog
  - name: netflow5
    port: 8877
    protocol: UDP
  - name: netflow9
    port: 4729
    protocol: UDP
  - name: sflow
    port: 6343
    protocol: UDP
  - name: ipfix
    port: 4738
    protocol: UDP
  - name: bmp
    port: 11019
    protocol: TCP
  - name: graphite
    port: 2003
    protocol: UDP
  - name: nxos-udp
    port: 50001
    protocol: UDP
  - name: nxos-grpc
    port: 50002
    protocol: TCP
  selector:
    app: minion
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app: onms
  name: opennms-core
  namespace: opennms
spec:
  clusterIP: None
  ports:
  - name: http
    port: 8980
  - name: karaf
    port: 8101
  selector:
    app: onms
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app: postgres
  name: postgresql
  namespace: opennms
spec:
  clusterIP: None
  ports:
  - port: 5432
  selector:
    app: postgres
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app: sentinel
  name: sentinel
  namespace: opennms
spec:
  clusterIP: None
  ports:
  - name: karaf
    port: 8301
    protocol: TCP
    targetPort: karaf
  - name: http
    port: 8181
    protocol: TCP
    targetPort: http
  selector:
    app: sentinel
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app: zk
  name: zookeeper
  namespace: opennms
spec:
  clusterIP: None
  ports:
  - name: client
    port: 2181
  - name: server
    port: 2888
  - name: leader-election
    port: 3888
  - name: jmx
    port: 9998
  selector:
    app: zk
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: event-watcher
  namespace: opennms
spec:
  replicas: 1
  selector:
    matchLabels:
      app: event-watcher
  template:
    metadata:
      labels:
        app: event-watcher
    spec:
      containers:
      - env:
        - name: TZ
          valueFrom:
            configMapKeyRef:
              key: TIMEZONE
              name: common-settings
        - name: ONMS_URL
          value: http://opennms-core.opennms.svc.cluster.local:8980/opennms
        - name: ONMS_USER
          value: admin
        - name: ONMS_PASSWD
          valueFrom:
            secretKeyRef:
              key: OPENNMS_UI_ADMIN_PASSWORD
              name: onms-passwords
        image: agalue/onms-k8s-watcher-go:latest
        imagePullPolicy: Always
        name: event-watcher
        resources:
          limits:
            cpu: 100m
            memory: 128Mi
      initContainers:
      - env:
        - name: TARGETS
          value: opennms-core.opennms.svc.cluster.local:8980
        - name: TIMEOUT
          value: "900"
        image: waisbrot/wait
        imagePullPolicy: IfNotPresent
        name: dependencies
      serviceAccountName: event-watcher-user
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: grafana
  name: grafana
  namespace: opennms
spec:
  replicas: 1
  selector:
    matchLabels:
      app: grafana
  template:
    metadata:
      labels:
        app: grafana
    spec:
      containers:
      - env:
        - name: TZ
          valueFrom:
            configMapKeyRef:
              key: TIMEZONE
              name: common-settings
        - name: DOMAIN
          valueFrom:
            configMapKeyRef:
              key: DOMAIN
              name: common-settings
        - name: GF_SECURITY_ADMIN_PASSWORD
          valueFrom:
            secretKeyRef:
              key: GRAFANA_UI_ADMIN_PASSWORD
              name: onms-passwords
        - name: GF_SERVER_DOMAIN
          value: grafana.$(DOMAIN)
        - name: GF_SERVER_ROOT_URL
          value: /
        - name: PGHOST
          value: postgresql.opennms.svc.cluster.local
        - name: PGPORT
          value: "5432"
        - name: GF_DATABASE_TYPE
          value: postgres
        - name: GF_DATABASE_SSL_MODE
          value: disable
        - name: GF_DATABASE_HOST
          value: $(PGHOST):$(PGPORT)
        - name: GF_DATABASE_NAME
          value: grafana
        - name: GF_DATABASE_USER
          valueFrom:
            secretKeyRef:
              key: GRAFANA_DB_USERNAME
              name: onms-passwords
        - name: GF_DATABASE_PASSWORD
          valueFrom:
            secretKeyRef:
              key: GRAFANA_DB_PASSWORD
              name: onms-passwords
        - name: GF_SESSION_PROVIDER
          value: postgres
        - name: GF_SESSION_PROVIDER_CONFIG
          value: dbname=$(GF_DATABASE_NAME) user=$(GF_DATABASE_USER) password=$(GF_DATABASE_PASSWORD)
            host=$(PGHOST) port=$(PGPORT) sslmode=$(GF_DATABASE_SSL_MODE)
        - name: GF_RENDERING_SERVER_URL
          value: http://grafana-renderer:8081/render
        - name: GF_RENDERING_CALLBACK_URL
          value: http://grafana:3000/
        image: opennms/helm:7.1.2
        imagePullPolicy: IfNotPresent
        livenessProbe:
          httpGet:
            path: /
            port: http
          initialDelaySeconds: 30
          periodSeconds: 60
        name: grafana-helm
        ports:
        - containerPort: 3000
          name: http
        readinessProbe:
          httpGet:
            path: /
            port: http
          initialDelaySeconds: 10
          periodSeconds: 10
        resources:
          limits:
            cpu: 200m
            memory: 256Mi
          requests:
            cpu: 100m
            memory: 128Mi
      initContainers:
      - env:
        - name: TARGETS
          value: postgresql.opennms.svc.cluster.local:5432
        - name: TIMEOUT
          value: "900"
        image: waisbrot/wait
        imagePullPolicy: IfNotPresent
        name: dependencies
      - command:
        - sh
        - /bin/grafana-init.sh
        env:
        - name: PGHOST
          value: postgresql.opennms.svc.cluster.local
        - name: PGPORT
          value: "5432"
        - name: PGUSER
          value: postgres
        - name: PGPASSWORD
          valueFrom:
            secretKeyRef:
              key: POSTGRES_PASSWORD
              name: onms-passwords
        - name: GF_DATABASE_NAME
          value: grafana
        - name: GF_DATABASE_USER
          valueFrom:
            secretKeyRef:
              key: GRAFANA_DB_USERNAME
              name: onms-passwords
        - name: GF_DATABASE_PASSWORD
          valueFrom:
            secretKeyRef:
              key: GRAFANA_DB_PASSWORD
              name: onms-passwords
        image: postgres:13
        imagePullPolicy: IfNotPresent
        name: init-database
        volumeMounts:
        - mountPath: /bin/grafana-init.sh
          name: init-scripts
          subPath: grafana-init.sh
      volumes:
      - configMap:
          name: init-scripts
        name: init-scripts
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: grafana-renderer
  name: grafana-renderer
  namespace: opennms
spec:
  replicas: 1
  selector:
    matchLabels:
      app: grafana-renderer
  template:
    metadata:
      labels:
        app: grafana-renderer
    spec:
      containers:
      - env:
        - name: BROWSER_TZ
          valueFrom:
            configMapKeyRef:
              key: TIMEZONE
              name: common-settings
        - name: ENABLE_METRICS
          value: "true"
        image: grafana/grafana-image-renderer:latest
        imagePullPolicy: IfNotPresent
        livenessProbe:
          httpGet:
            path: /
            port: http
          initialDelaySeconds: 30
          periodSeconds: 60
        name: grafana-renderer
        ports:
        - containerPort: 8081
          name: http
        readinessProbe:
          httpGet:
            path: /
            port: http
          initialDelaySeconds: 10
          periodSeconds: 10
        resources:
          limits:
            cpu: 200m
            memory: 256Mi
          requests:
            cpu: 100m
            memory: 128Mi
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: grpc-server
  name: grpc-server
  namespace: opennms
spec:
  replicas: 1
  selector:
    matchLabels:
      app: grpc-server
  template:
    metadata:
      labels:
        app: grpc-server
    spec:
      containers:
      - env:
        - name: TZ
          valueFrom:
            configMapKeyRef:
              key: TIMEZONE
              name: common-settings
        - name: PORT
          value: "8990"
        - name: HTTP_PORT
          value: "2112"
        - name: BOOTSTRAP_SERVER
          value: kafka.opennms.svc.cluster.local:9092
        - name: TLS_ENABLED
          value: "false"
        - name: INSTANCE_ID
          valueFrom:
            configMapKeyRef:
              key: OPENNMS_INSTANCE_ID
              name: common-settings
        - name: MAX_MESSAGE_SIZE
          value: "4194304"
        - name: CONSUMER_SECURITY_PROTOCOL
          value: SASL_PLAINTEXT
        - name: CONSUMER_SASL_MECHANISM
          value: PLAIN
        - name: CONSUMER_SASL_USERNAME
          valueFrom:
            secretKeyRef:
              key: KAFKA_CLIENT_USER
              name: onms-passwords
        - name: CONSUMER_SASL_PASSWORD
          valueFrom:
            secretKeyRef:
              key: KAFKA_CLIENT_PASSWORD
              name: onms-passwords
        - name: CONSUMER_AUTO_OFFSET_RESET
          value: latest
        - name: CONSUMER_MAX_PARTITION_FETCH_BYTES
          value: "5000000"
        - name: PRODUCER_SECURITY_PROTOCOL
          value: SASL_PLAINTEXT
        - name: PRODUCER_SASL_MECHANISM
          value: PLAIN
        - name: PRODUCER_SASL_USERNAME
          valueFrom:
            secretKeyRef:
              key: KAFKA_CLIENT_USER
              name: onms-passwords
        - name: PRODUCER_SASL_PASSWORD
          valueFrom:
            secretKeyRef:
              key: KAFKA_CLIENT_PASSWORD
              name: onms-passwords
        - name: PRODUCER_MESSAGE_MAX_BYTES
          value: "5000000"
        image: agalue/onms-grpc-server
        imagePullPolicy: Always
        livenessProbe:
          exec:
            command:
            - /bin/grpc_health_probe
            - -addr
            - :8990
            - -rpc-timeout
            - 2s
          initialDelaySeconds: 30
          periodSeconds: 30
          timeoutSeconds: 3
        name: grpc-server
        ports:
        - containerPort: 8990
          name: http
        - containerPort: 2112
          name: prometheus
        readinessProbe:
          exec:
            command:
            - /bin/grpc_health_probe
            - -addr
            - :8990
            - -rpc-timeout
            - 2s
          initialDelaySeconds: 20
          periodSeconds: 10
          timeoutSeconds: 3
        resources:
          limits:
            cpu: 50m
            memory: 64Mi
          requests:
            cpu: 20m
            memory: 32Mi
      initContainers:
      - env:
        - name: TARGETS
          value: kafka.opennms.svc.cluster.local:9092
        - name: TIMEOUT
          value: "900"
        image: waisbrot/wait
        imagePullPolicy: IfNotPresent
        name: dependencies
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: kafka-manager
  name: kafka-manager
  namespace: opennms
spec:
  replicas: 1
  selector:
    matchLabels:
      app: kafka-manager
  template:
    metadata:
      labels:
        app: kafka-manager
    spec:
      containers:
      - env:
        - name: TZ
          valueFrom:
            configMapKeyRef:
              key: TIMEZONE
              name: common-settings
        - name: ZK_HOSTS
          value: zookeeper.opennms.svc.cluster.local:2181
        - name: KAFKA_MANAGER_AUTH_ENABLED
          value: "true"
        - name: KAFKA_MANAGER_USERNAME
          valueFrom:
            secretKeyRef:
              key: KAFKA_MANAGER_USERNAME
              name: onms-passwords
        - name: KAFKA_MANAGER_PASSWORD
          valueFrom:
            secretKeyRef:
              key: KAFKA_MANAGER_PASSWORD
              name: onms-passwords
        - name: APPLICATION_SECRET
          valueFrom:
            secretKeyRef:
              key: KAFKA_MANAGER_APPLICATION_SECRET
              name: onms-passwords
        image: hlebalbau/kafka-manager:stable
        imagePullPolicy: IfNotPresent
        livenessProbe:
          initialDelaySeconds: 30
          periodSeconds: 60
          tcpSocket:
            port: http
        name: kafka-manager
        ports:
        - containerPort: 9000
          name: http
        readinessProbe:
          initialDelaySeconds: 10
          periodSeconds: 10
          tcpSocket:
            port: http
        resources:
          limits:
            cpu: 200m
            memory: 512Mi
          requests:
            cpu: 100m
            memory: 256Mi
      initContainers:
      - env:
        - name: TARGETS
          value: kafka.opennms.svc.cluster.local:9092
        - name: TIMEOUT
          value: "900"
        image: waisbrot/wait
        imagePullPolicy: IfNotPresent
        name: dependencies
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: kafka-producer-enhancer
  name: kafka-producer-enhancer
  namespace: opennms
spec:
  replicas: 1
  selector:
    matchLabels:
      app: kafka-producer-enhancer
  template:
    metadata:
      labels:
        app: kafka-producer-enhancer
    spec:
      containers:
      - env:
        - name: INSTANCE_ID
          valueFrom:
            configMapKeyRef:
              key: OPENNMS_INSTANCE_ID
              name: common-settings
        - name: BOOTSTRAP_SERVER
          value: kafka.opennms.svc.cluster.local:9092
        - name: GROUP_ID
          value: alarms-enhancer-group
        - name: TARGET_KIND
          value: alarms
        - name: TARGET_TOPIC
          value: $(INSTANCE_ID)_enhanced_alarms
        - name: NODES_TOPIC
          value: $(INSTANCE_ID)_nodes
        - name: ALARMS_TOPIC
          value: $(INSTANCE_ID)_alarms
        image: agalue/producer-enhancer-go:latest
        imagePullPolicy: Always
        name: kafka-producer-enhancer
        resources:
          limits:
            cpu: 100m
            memory: 128Mi
      initContainers:
      - env:
        - name: TARGETS
          value: opennms-core.opennms.svc.cluster.local:8980
        - name: TIMEOUT
          value: "900"
        image: waisbrot/wait
        imagePullPolicy: IfNotPresent
        name: dependencies
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  labels:
    app: cassandra
  name: cassandra
  namespace: opennms
spec:
  replicas: 1
  selector:
    matchLabels:
      app: cassandra
  serviceName: cassandra
  template:
    metadata:
      labels:
        app: cassandra
    spec:
      containers:
      - env:
        - name: TZ
          valueFrom:
            configMapKeyRef:
              key: TIMEZONE
              name: common-settings
        - name: LOCAL_JMX
          value: "no"
        - name: MEM_TOTAL_MB
          valueFrom:
            resourceFieldRef:
              divisor: 1Mi
              resource: requests.memory
        - name: MAX_HEAP_SIZE
          value: $(MEM_TOTAL_MB)m
        - name: HEAP_NEWSIZE
          value: $(MEM_TOTAL_MB)m
        - name: CASSANDRA_SEEDS
          value: cassandra-0.cassandra.opennms.svc.cluster.local
        - name: CASSANDRA_NUM_TOKENS
          value: "16"
        - name: CASSANDRA_CLUSTER_NAME
          valueFrom:
            configMapKeyRef:
              key: CASSANDRA_CLUSTER_NAME
              name: common-settings
        - name: CASSANDRA_LISTEN_ADDRESS
          valueFrom:
            fieldRef:
              fieldPath: status.podIP
        - name: CASSANDRA_ENDPOINT_SNITCH
          value: GossipingPropertyFileSnitch
        - name: CASSANDRA_DC
          valueFrom:
            configMapKeyRef:
              key: CASSANDRA_DC
              name: common-settings
        - name: CASSANDRA_RACK
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        image: cassandra:4.0
        imagePullPolicy: IfNotPresent
        lifecycle:
          preStop:
            exec:
              command:
              - nodetool -u cassandra -pw cassandra drain
        livenessProbe:
          initialDelaySeconds: 90
          periodSeconds: 60
          tcpSocket:
            port: cql
        name: cassandra
        ports:
        - containerPort: 7000
          name: intra-node
        - containerPort: 7001
          name: tls-intra-node
        - containerPort: 7199
          name: jmx
        - containerPort: 9042
          name: cql
        readinessProbe:
          exec:
            command:
            - bash
            - /ready-probe.sh
          initialDelaySeconds: 60
          periodSeconds: 15
          timeoutSeconds: 5
        resources:
          limits:
            cpu: 1000m
            memory: 3Gi
          requests:
            cpu: 250m
            memory: 2Gi
        securityContext:
          capabilities:
            add:
            - IPC_LOCK
          runAsUser: 999
        volumeMounts:
        - mountPath: /cassandra_data
          name: data
        - mountPath: /ready-probe.sh
          name: cassandra-config
          subPath: ready-probe.sh
        - mountPath: /etc/cassandra/jmxremote.password
          name: cassandra-config
          subPath: jmxremote.password
        - mountPath: /etc/cassandra/jvm11-server.options
          name: cassandra-config
          subPath: jvm11-server.options
        - mountPath: /etc/cassandra/jvm.options
          name: cassandra-config
          subPath: jvm.options
      initContainers:
      - command:
        - sysctl
        - -w
        - vm.max_map_count=262144
        image: busybox
        name: init-sysctl
        securityContext:
          privileged: true
      securityContext:
        fsGroup: 999
      terminationGracePeriodSeconds: 1800
      volumes:
      - configMap:
          name: cassandra-config
        name: cassandra-config
  volumeClaimTemplates:
  - metadata:
      name: data
    spec:
      accessModes:
      - ReadWriteOnce
      resources:
        requests:
          storage: 20Gi
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  labels:
    app: elasticsearch
    role: esdata
  name: esdata
  namespace: opennms
spec:
  replicas: 1
  selector:
    matchLabels:
      role: esdata
  serviceName: esdata
  template:
    metadata:
      labels:
        app: elasticsearch
        role: esdata
    spec:
      containers:
      - env:
        - name: node.master
          value: "true"
        - name: discovery.type
          value: single-node
        - name: bootstrap.memory_lock
          value: "false"
        - name: TZ
          valueFrom:
            configMapKeyRef:
              key: TIMEZONE
              name: common-settings
        - name: cluster.name
          value: OpenNMS
        - name: node.name
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: node.data
          value: "true"
        - name: node.ingest
          value: "true"
        - name: http.cors.enabled
          value: "true"
        - name: http.cors.allow-origin
          value: '*'
        - name: xpack.monitoring.collection.enabled
          value: "true"
        - name: search.max_buckets
          value: "50000"
        - name: MEM_TOTAL_MB
          valueFrom:
            resourceFieldRef:
              divisor: 1Mi
              resource: requests.memory
        - name: ES_JAVA_OPTS
          value: -Xms$(MEM_TOTAL_MB)m -Xmx$(MEM_TOTAL_MB)m
        - name: ELASTIC_PASSWORD
          valueFrom:
            secretKeyRef:
              key: ELASTICSEARCH_PASSWORD
              name: onms-passwords
        image: docker.elastic.co/elasticsearch/elasticsearch:7.6.2
        imagePullPolicy: IfNotPresent
        livenessProbe:
          initialDelaySeconds: 60
          periodSeconds: 60
          tcpSocket:
            port: http
        name: esdata
        ports:
        - containerPort: 9200
          name: http
        - containerPort: 9300
          name: transport
        readinessProbe:
          initialDelaySeconds: 30
          periodSeconds: 15
          tcpSocket:
            port: http
        resources:
          limits:
            cpu: 500m
            memory: 2Gi
          requests:
            cpu: 250m
            memory: 1Gi
        securityContext:
          capabilities:
            add:
            - IPC_LOCK
            - SYS_RESOURCE
          runAsUser: 1000
        volumeMounts:
        - mountPath: /usr/share/elasticsearch/data
          name: data
        - mountPath: /usr/share/elasticsearch/plugins/drift
          name: onms-plugin-dir
      initContainers:
      - command:
        - sysctl
        - -w
        - vm.max_map_count=262144
        image: busybox
        name: init-sysctl
        securityContext:
          privileged: true
      - args:
        - wget $(PLUGIN_URL) && unzip elasticsearch-drift-plugin-$(PLUGIN_VERSION).zip
          -d /plugin/
        command:
        - sh
        - -c
        env:
        - name: PLUGIN_VERSION
          value: 7.6.2
        - name: PLUGIN_URL
          value: https://github.com/OpenNMS/elasticsearch-drift-plugin/releases/download/v$(PLUGIN_VERSION)/elasticsearch-drift-plugin-$(PLUGIN_VERSION).zip
        image: busybox
        name: onms-plugin
        volumeMounts:
        - mountPath: /plugin
          name: onms-plugin-dir
      securityContext:
        fsGroup: 1000
      terminationGracePeriodSeconds: 300
      volumes:
      - emptyDir: {}
        name: onms-plugin-dir
  volumeClaimTemplates:
  - metadata:
      name: data
    spec:
      accessModes:
      - ReadWriteOnce
      resources:
        requests:
          storage: 20Gi
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  labels:
    app: kafka
  name: kafka
  namespace: opennms
spec:
  replicas: 1
  selector:
    matchLabels:
      app: kafka
  serviceName: kafka
  template:
    metadata:
      labels:
        app: kafka
    spec:
      containers:
      - env:
        - name: KAFKA_DEFAULT_REPLICATION_FACTOR
          value: "1"
        - name: KAFKA_MIN_INSYNC_REPLICAS
          value: "1"
        - name: TZ
          valueFrom:
            configMapKeyRef:
              key: TIMEZONE
              name: common-settings
        - name: POD_IP
          valueFrom:
            fieldRef:
              fieldPath: status.podIP
        - name: BROKER_ID_COMMAND
          value: echo ${HOSTNAME##*-}
        - name: ALLOW_PLAINTEXT_LISTENER
          value: "yes"
        - name: KAFKA_CLIENT_USERS
          valueFrom:
            secretKeyRef:
              key: KAFKA_CLIENT_USER
              name: onms-passwords
        - name: KAFKA_CLIENT_PASSWORDS
          valueFrom:
            secretKeyRef:
              key: KAFKA_CLIENT_PASSWORD
              name: onms-passwords
        - name: KAFKA_INTER_BROKER_USER
          valueFrom:
            secretKeyRef:
              key: KAFKA_INTER_BROKER_USER
              name: onms-passwords
        - name: KAFKA_INTER_BROKER_PASSWORD
          valueFrom:
            secretKeyRef:
              key: KAFKA_INTER_BROKER_PASSWORD
              name: onms-passwords
        - name: KAFKA_CFG_LISTENERS
          value: CLIENT://:9092,INTERNAL://:9093
        - name: KAFKA_CFG_ADVERTISED_LISTENERS
          value: CLIENT://:9092,INTERNAL://:9093
        - name: KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP
          value: CLIENT:SASL_PLAINTEXT,INTERNAL:SASL_PLAINTEXT
        - name: KAFKA_CFG_INTER_BROKER_LISTENER_NAME
          value: INTERNAL
        - name: KAFKA_CFG_SASL_MECHANISM_INTER_BROKER_PROTOCOL
          value: PLAIN
        - name: KAFKA_CFG_SASL_ENABLED_MECHANISMS
          value: PLAIN
        - name: KAFKA_CFG_ZOOKEEPER_CONNECTION_TIMEOUT_MS
          value: "30000"
        - name: KAFKA_CFG_ZOOKEEPER_CONNECT
          value: zookeeper.opennms.svc.cluster.local:2181/kafka
        - name: KAFKA_CFG_DEFAULT_REPLICATION_FACTOR
          valueFrom:
            configMapKeyRef:
              key: KAFKA_REPLICATION_FACTOR
              name: common-settings
        - name: KAFKA_CFG_MIN_INSYNC_REPLICAS
          value: "1"
        - name: KAFKA_CFG_NUM_PARTITIONS
          valueFrom:
            configMapKeyRef:
              key: KAFKA_NUM_PARTITIONS
              name: common-settings
        - name: KAFKA_CFG_AUTO_LEADER_REBALANCE_ENABLE
          value: "true"
        - name: KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE
          value: "true"
        - name: KAFKA_CFG_DELETE_TOPIC_ENABLE
          value: "false"
        - name: KAFKA_CFG_CONTROLLED_SHUTDOWN_ENABLE
          value: "true"
        - name: KAFKA_CFG_MESSAGE_MAX_BYTES
          value: "5000000"
        - name: KAFKA_CFG_REPLICA_FETCH_MAX_BYTES
          value: "5000000"
        - name: KAFKA_CFG_COMPRESSION_TYPE
          value: producer
        - name: JMX_PORT
          value: "9999"
        - name: MEM_TOTAL_MB
          valueFrom:
            resourceFieldRef:
              divisor: 1Mi
              resource: requests.memory
        - name: KAFKA_HEAP_OPTS
          value: -Xms$(MEM_TOTAL_MB)m -Xmx$(MEM_TOTAL_MB)m -Dcom.sun.management.jmxremote.rmi.port=$(JMX_PORT)
            -Djava.rmi.server.hostname=$(POD_IP)
        image: bitnami/kafka:2.8.1
        imagePullPolicy: IfNotPresent
        livenessProbe:
          initialDelaySeconds: 30
          periodSeconds: 60
          tcpSocket:
            port: client
        name: kafka
        ports:
        - containerPort: 9092
          name: client
        - containerPort: 9999
          name: jmx
        readinessProbe:
          initialDelaySeconds: 20
          periodSeconds: 10
          tcpSocket:
            port: client
        resources:
          limits:
            cpu: 200m
            memory: 1Gi
          requests:
            cpu: 100m
            memory: 512Mi
        volumeMounts:
        - mountPath: /bitnami/kafka
          name: data
      initContainers:
      - env:
        - name: TARGETS
          value: zookeeper.opennms.svc.cluster.local:2181
        - name: TIMEOUT
          value: "900"
        image: waisbrot/wait
        imagePullPolicy: IfNotPresent
        name: dependencies
      securityContext:
        fsGroup: 1001
      terminationGracePeriodSeconds: 300
      volumes:
      - name: config
        secret:
          secretName: onms-passwords
  volumeClaimTemplates:
  - metadata:
      name: data
    spec:
      accessModes:
      - ReadWriteOnce
      resources:
        requests:
          storage: 20Gi
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  labels:
    app: minion
  name: minion
  namespace: opennms
spec:
  podManagementPolicy: Parallel
  replicas: 1
  selector:
    matchLabels:
      app: minion
  serviceName: minion
  template:
    metadata:
      labels:
        app: minion
    spec:
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: app
                  operator: In
                  values:
                  - onms
              topologyKey: kubernetes.io/hostname
            weight: 100
      containers:
      - args:
        - -c
        env:
        - name: TZ
          valueFrom:
            configMapKeyRef:
              key: TIMEZONE
              name: common-settings
        - name: MINION_ID
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: MINION_LOCATION
          valueFrom:
            configMapKeyRef:
              key: MINION_LOCATION
              name: common-settings
        - name: OPENNMS_HTTP_URL
          value: http://opennms-core.opennms.svc.cluster.local:8980/opennms
        - name: OPENNMS_HTTP_USER
          value: admin
        - name: OPENNMS_HTTP_PASS
          valueFrom:
            secretKeyRef:
              key: OPENNMS_UI_ADMIN_PASSWORD
              name: onms-passwords
        - name: MEM_TOTAL_MB
          valueFrom:
            resourceFieldRef:
              divisor: 1Mi
              resource: requests.memory
        - name: JAVA_OPTS
          value: -Xms$(MEM_TOTAL_MB)m -Xmx$(MEM_TOTAL_MB)m -XX:+AlwaysPreTouch -XX:+UseG1GC
            -XX:+UseStringDeduplication
        - name: MAX_FD
          value: "65536"
        image: opennms/minion:28.1.1
        imagePullPolicy: IfNotPresent
        livenessProbe:
          exec:
            command:
            - /health.sh
          initialDelaySeconds: 60
          periodSeconds: 60
          timeoutSeconds: 15
        name: minion
        ports:
        - containerPort: 1162
          name: traps
          protocol: UDP
        - containerPort: 1514
          name: syslog
          protocol: UDP
        - containerPort: 8181
          name: http
          protocol: TCP
        - containerPort: 8201
          name: karaf
          protocol: TCP
        - containerPort: 50001
          name: nxos-udp
          protocol: UDP
        - containerPort: 8877
          name: netflow5
          protocol: UDP
        - containerPort: 4729
          name: netflow9
          protocol: UDP
        - containerPort: 6343
          name: sflow
          protocol: UDP
        - containerPort: 4738
          name: ipfix
          protocol: UDP
        - containerPort: 2003
          name: graphite
          protocol: UDP
        - containerPort: 11019
          name: bmp
          protocol: TCP
        readinessProbe:
          exec:
            command:
            - /health.sh
          initialDelaySeconds: 30
          periodSeconds: 10
        resources:
          limits:
            cpu: 250m
            memory: 1Gi
          requests:
            cpu: 100m
            memory: 512Mi
        volumeMounts:
        - mountPath: /opt/minion-etc-overlay
          name: etc-overlay
      - env:
        - name: TZ
          valueFrom:
            configMapKeyRef:
              key: TIMEZONE
              name: common-settings
        - name: BOOTSTRAP_SERVERS
          value: kafka.opennms.svc.cluster.local:9092
        - name: MINION_LOCATION
          valueFrom:
            configMapKeyRef:
              key: MINION_LOCATION
              name: common-settings
        - name: INSTANCE_ID
          valueFrom:
            configMapKeyRef:
              key: OPENNMS_INSTANCE_ID
              name: common-settings
        - name: MINION_ID
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: PORT
          value: "50002"
        - name: TOPIC
          value: $(INSTANCE_ID).Sink.Telemetry-NXOS
        - name: KAFKA_SECURITY_PROTOCOL
          value: SASL_PLAINTEXT
        - name: KAFKA_SASL_MECHANISM
          value: PLAIN
        - name: KAFKA_SASL_USERNAME
          valueFrom:
            secretKeyRef:
              key: KAFKA_CLIENT_USER
              name: onms-passwords
        - name: KAFKA_SASL_PASSWORD
          valueFrom:
            secretKeyRef:
              key: KAFKA_CLIENT_PASSWORD
              name: onms-passwords
        image: agalue/opennms-nxos-grpc-go:latest
        imagePullPolicy: Always
        livenessProbe:
          initialDelaySeconds: 20
          periodSeconds: 30
          tcpSocket:
            port: nxos-grpc
        name: nxos-grpc
        ports:
        - containerPort: 50002
          name: nxos-grpc
          protocol: TCP
        readinessProbe:
          initialDelaySeconds: 5
          periodSeconds: 10
          tcpSocket:
            port: nxos-grpc
      initContainers:
      - env:
        - name: TARGETS
          value: kafka.opennms.svc.cluster.local:9092,opennms-core.opennms.svc.cluster.local:8980
        - name: TIMEOUT
          value: "900"
        image: waisbrot/wait
        imagePullPolicy: IfNotPresent
        name: dependencies
      - command:
        - bash
        - /init.sh
        env:
        - name: TZ
          valueFrom:
            configMapKeyRef:
              key: TIMEZONE
              name: common-settings
        - name: INSTANCE_ID
          valueFrom:
            configMapKeyRef:
              key: OPENNMS_INSTANCE_ID
              name: common-settings
        - name: KAFKA_SERVER
          value: kafka.opennms.svc.cluster.local
        - name: KAFKA_SASL_USERNAME
          valueFrom:
            secretKeyRef:
              key: KAFKA_CLIENT_USER
              name: onms-passwords
        - name: KAFKA_SASL_PASSWORD
          valueFrom:
            secretKeyRef:
              key: KAFKA_CLIENT_PASSWORD
              name: onms-passwords
        - name: JAEGER_AGENT_HOST
          value: onms-tracing-agent.opennms.svc.cluster.local
        image: bash
        imagePullPolicy: IfNotPresent
        name: init-config
        volumeMounts:
        - mountPath: /etc-overlay
          name: etc-overlay
        - mountPath: /init.sh
          name: init-scripts
          subPath: onms-minion-init.sh
      terminationGracePeriodSeconds: 60
      volumes:
      - emptyDir: {}
        name: etc-overlay
      - configMap:
          name: init-scripts
        name: init-scripts
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  labels:
    app: onms
  name: onms
  namespace: opennms
spec:
  replicas: 1
  selector:
    matchLabels:
      app: onms
  serviceName: opennms-core
  template:
    metadata:
      labels:
        app: onms
    spec:
      containers:
      - args:
        - -s
        env:
        - name: TZ
          valueFrom:
            configMapKeyRef:
              key: TIMEZONE
              name: common-settings
        - name: MEM_TOTAL_MB
          valueFrom:
            resourceFieldRef:
              divisor: 1Mi
              resource: requests.memory
        - name: JMX_PORT
          value: "18980"
        - name: JAVA_OPTS
          value: -Xms$(MEM_TOTAL_MB)m -Xmx$(MEM_TOTAL_MB)m -XX:+AlwaysPreTouch -XX:+UseG1GC
            -XX:+UseStringDeduplication -Xlog:gc*,gc+phases=debug:file=/opt/opennms/logs/gc.log:time,pid,tags:filecount=10,filesize=10m
            -Dcom.sun.management.jmxremote.port=$(JMX_PORT) -Dcom.sun.management.jmxremote.rmi.port=$(JMX_PORT)
            -Dcom.sun.management.jmxremote.local.only=false -Dcom.sun.management.jmxremote.ssl=false
            -Dcom.sun.management.jmxremote.authenticate=true
        - name: POSTGRES_HOST
          value: postgresql.opennms.svc.cluster.local
        - name: POSTGRES_PORT
          value: "5432"
        - name: POSTGRES_USER
          value: postgres
        - name: POSTGRES_PASSWORD
          valueFrom:
            secretKeyRef:
              key: POSTGRES_PASSWORD
              name: onms-passwords
        - name: OPENNMS_DBNAME
          value: opennms
        - name: OPENNMS_DBUSER
          value: opennms
        - name: OPENNMS_DBPASS
          valueFrom:
            secretKeyRef:
              key: OPENNMS_DB_PASSWORD
              name: onms-passwords
        image: opennms/horizon:28.1.1
        imagePullPolicy: IfNotPresent
        livenessProbe:
          httpGet:
            path: /opennms/login.jsp
            port: http
          initialDelaySeconds: 30
          periodSeconds: 60
        name: onms
        ports:
        - containerPort: 8101
          name: karaf
        - containerPort: 8980
          name: http
        - containerPort: 18980
          name: jmx
        readinessProbe:
          httpGet:
            path: /opennms/login.jsp
            port: http
          initialDelaySeconds: 15
          periodSeconds: 15
        resources:
          limits:
            cpu: 1000m
            memory: 3Gi
          requests:
            cpu: 500m
            memory: 2Gi
        volumeMounts:
        - mountPath: /opt/opennms/etc
          name: etc
        - mountPath: /opt/opennms/deploy
          name: karaf-deploy
        - mountPath: /opennms-data/kafka
          name: kafka-state
      initContainers:
      - command:
        - bash
        - /init.sh
        env:
        - name: TZ
          valueFrom:
            configMapKeyRef:
              key: TIMEZONE
              name: common-settings
        - name: INSTANCE_ID
          valueFrom:
            configMapKeyRef:
              key: OPENNMS_INSTANCE_ID
              name: common-settings
        - name: ENABLE_ALEC
          value: "true"
        - name: FEATURES_LIST
          value: opennms-alarm-history-elastic,opennms-es-rest,opennms-kafka-producer,opennms-situation-feedback
        - name: CASSANDRA_SERVER
          value: cassandra.opennms.svc.cluster.local
        - name: CASSANDRA_REPLICATION_FACTOR
          valueFrom:
            configMapKeyRef:
              key: CASSANDRA_REPLICATION_FACTOR
              name: common-settings
        - name: CASSANDRA_DC
          valueFrom:
            configMapKeyRef:
              key: CASSANDRA_DC
              name: common-settings
        - name: KAFKA_SERVER
          value: kafka.opennms.svc.cluster.local
        - name: KAFKA_SASL_USERNAME
          valueFrom:
            secretKeyRef:
              key: KAFKA_CLIENT_USER
              name: onms-passwords
        - name: KAFKA_SASL_PASSWORD
          valueFrom:
            secretKeyRef:
              key: KAFKA_CLIENT_PASSWORD
              name: onms-passwords
        - name: ELASTIC_SERVER
          value: esdata.opennms.svc.cluster.local
        - name: ELASTIC_PASSWORD
          valueFrom:
            secretKeyRef:
              key: ELASTICSEARCH_PASSWORD
              name: onms-passwords
        - name: ELASTIC_INDEX_STRATEGY_FLOWS
          valueFrom:
            configMapKeyRef:
              key: ELASTIC_INDEX_STRATEGY_FLOWS
              name: common-settings
        - name: ELASTIC_REPLICATION_FACTOR
          valueFrom:
            configMapKeyRef:
              key: ELASTIC_REPLICATION_FACTOR
              name: common-settings
        - name: ELASTIC_NUM_SHARDS
          valueFrom:
            configMapKeyRef:
              key: ELASTIC_NUM_SHARDS
              name: common-settings
        - name: JAEGER_AGENT_HOST
          value: onms-tracing-agent.opennms.svc.cluster.local
        image: opennms/horizon:28.1.1
        imagePullPolicy: IfNotPresent
        name: init-config
        securityContext:
          runAsNonRoot: false
          runAsUser: 0
        volumeMounts:
        - mountPath: /opennms-etc
          name: etc
        - mountPath: /init.sh
          name: init-scripts
          subPath: onms-core-init.sh
      - env:
        - name: TARGETS
          value: postgresql.opennms.svc.cluster.local:5432,cassandra.opennms.svc.cluster.local:9042,kafka.opennms.svc.cluster.local:9092,esdata.opennms.svc.cluster.local:9200
        - name: TIMEOUT
          value: "900"
        image: waisbrot/wait
        imagePullPolicy: IfNotPresent
        name: dependencies
      - args:
        - cd /plugin && wget -q -nc --no-check-certificate $ALEC_KAR_URL
        command:
        - sh
        - -c
        env:
        - name: ALEC_KAR_URL
          value: https://github.com/OpenNMS/alec/releases/download/v1.1.1/opennms-alec-plugin.kar
        image: busybox
        name: alec-plugin
        volumeMounts:
        - mountPath: /plugin
          name: karaf-deploy
      - command:
        - sh
        - -c
        - cqlsh -f /opennms-etc/newts.cql $CASSANDRA_HOST
        env:
        - name: CASSANDRA_HOST
          value: cassandra.opennms.svc.cluster.local
        image: cassandra:4.0
        imagePullPolicy: IfNotPresent
        name: init-newts
        volumeMounts:
        - mountPath: /opennms-etc
          name: etc
      securityContext:
        fsGroup: 10001
      terminationGracePeriodSeconds: 120
      volumes:
      - configMap:
          name: init-scripts
        name: init-scripts
      - emptyDir: {}
        name: karaf-deploy
  volumeClaimTemplates:
  - metadata:
      name: etc
    spec:
      accessModes:
      - ReadWriteOnce
      resources:
        requests:
          storage: 1Gi
  - metadata:
      name: kafka-state
    spec:
      accessModes:
      - ReadWriteOnce
      resources:
        requests:
          storage: 2Gi
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  labels:
    app: postgres
    role: master
  name: postgres
  namespace: opennms
spec:
  replicas: 1
  selector:
    matchLabels:
      app: postgres
  serviceName: postgresql
  template:
    metadata:
      labels:
        app: postgres
        role: master
    spec:
      containers:
      - args:
        - postgres
        env:
        - name: TZ
          valueFrom:
            configMapKeyRef:
              key: TIMEZONE
              name: common-settings
        - name: POSTGRES_USER
          value: postgres
        - name: POSTGRES_PASSWORD
          valueFrom:
            secretKeyRef:
              key: POSTGRES_PASSWORD
              name: onms-passwords
        - name: PGDATA
          value: /var/lib/postgresql/data/pgdata
        image: postgres:13
        imagePullPolicy: IfNotPresent
        livenessProbe:
          exec:
            command:
            - sh
            - -c
            - exec pg_isready --host $HOSTNAME
          initialDelaySeconds: 30
          periodSeconds: 60
        name: postgres
        ports:
        - containerPort: 5432
          name: pg
        readinessProbe:
          exec:
            command:
            - sh
            - -c
            - exec pg_isready --host $HOSTNAME
          initialDelaySeconds: 10
          periodSeconds: 10
        resources:
          limits:
            cpu: 200m
            memory: 256Mi
          requests:
            cpu: 100m
            memory: 128Mi
        volumeMounts:
        - mountPath: /var/lib/postgresql/data
          name: data
      volumes: []
  volumeClaimTemplates:
  - metadata:
      name: data
    spec:
      accessModes:
      - ReadWriteOnce
      resources:
        requests:
          storage: 20Gi
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  labels:
    app: sentinel
  name: sentinel
  namespace: opennms
spec:
  podManagementPolicy: Parallel
  replicas: 1
  selector:
    matchLabels:
      app: sentinel
  serviceName: sentinel
  template:
    metadata:
      labels:
        app: sentinel
    spec:
      containers:
      - args:
        - -c
        env:
        - name: TZ
          valueFrom:
            configMapKeyRef:
              key: TIMEZONE
              name: common-settings
        - name: SENTINEL_ID
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: SENTINEL_LOCATION
          valueFrom:
            configMapKeyRef:
              key: MINION_LOCATION
              name: common-settings
        - name: POSTGRES_HOST
          value: postgresql.opennms.svc.cluster.local
        - name: POSTGRES_PORT
          value: "5432"
        - name: POSTGRES_USER
          value: postgres
        - name: POSTGRES_PASSWORD
          valueFrom:
            secretKeyRef:
              key: POSTGRES_PASSWORD
              name: onms-passwords
        - name: POSTGRES_DB
          value: opennms
        - name: OPENNMS_HTTP_URL
          value: http://opennms-core.opennms.svc.cluster.local:8980/opennms
        - name: OPENNMS_HTTP_USER
          value: admin
        - name: OPENNMS_HTTP_PASS
          valueFrom:
            secretKeyRef:
              key: OPENNMS_UI_ADMIN_PASSWORD
              name: onms-passwords
        - name: MEM_TOTAL_MB
          valueFrom:
            resourceFieldRef:
              divisor: 1Mi
              resource: requests.memory
        - name: JAVA_OPTS
          value: -Xms$(MEM_TOTAL_MB)m -Xmx$(MEM_TOTAL_MB)m -XX:+AlwaysPreTouch -XX:+UseG1GC
            -XX:+UseStringDeduplication -Dcom.datastax.driver.FORCE_NIO=true
        - name: MAX_FD
          value: "65536"
        image: opennms/sentinel:28.1.1
        imagePullPolicy: IfNotPresent
        livenessProbe:
          exec:
            command:
            - /health.sh
          initialDelaySeconds: 60
          periodSeconds: 60
          timeoutSeconds: 15
        name: sentinel
        ports:
        - containerPort: 8181
          name: http
        - containerPort: 8301
          name: karaf
        readinessProbe:
          exec:
            command:
            - /health.sh
          initialDelaySeconds: 60
          periodSeconds: 15
        resources:
          limits:
            cpu: 250m
            memory: 1Gi
          requests:
            cpu: 100m
            memory: 512Mi
        volumeMounts:
        - mountPath: /opt/sentinel-etc-overlay
          name: etc-overlay
      initContainers:
      - env:
        - name: TARGETS
          value: opennms-core.opennms.svc.cluster.local:8980
        - name: TIMEOUT
          value: "900"
        image: waisbrot/wait
        imagePullPolicy: IfNotPresent
        name: dependencies
      - command:
        - bash
        - /init.sh
        env:
        - name: TZ
          valueFrom:
            configMapKeyRef:
              key: TIMEZONE
              name: common-settings
        - name: INSTANCE_ID
          valueFrom:
            configMapKeyRef:
              key: OPENNMS_INSTANCE_ID
              name: common-settings
        - name: USE_NEPHRON
          value: "true"
        - name: KAFKA_SERVER
          value: kafka.opennms.svc.cluster.local
        - name: KAFKA_SASL_USERNAME
          valueFrom:
            secretKeyRef:
              key: KAFKA_CLIENT_USER
              name: onms-passwords
        - name: KAFKA_SASL_PASSWORD
          valueFrom:
            secretKeyRef:
              key: KAFKA_CLIENT_PASSWORD
              name: onms-passwords
        - name: CASSANDRA_SERVER
          value: cassandra.opennms.svc.cluster.local
        - name: ELASTIC_SERVER
          value: esdata.opennms.svc.cluster.local
        - name: ELASTIC_PASSWORD
          valueFrom:
            secretKeyRef:
              key: ELASTICSEARCH_PASSWORD
              name: onms-passwords
        - name: ELASTIC_INDEX_STRATEGY_FLOWS
          valueFrom:
            configMapKeyRef:
              key: ELASTIC_INDEX_STRATEGY_FLOWS
              name: common-settings
        - name: ELASTIC_REPLICATION_FACTOR
          valueFrom:
            configMapKeyRef:
              key: ELASTIC_REPLICATION_FACTOR
              name: common-settings
        - name: ELASTIC_NUM_SHARDS
          valueFrom:
            configMapKeyRef:
              key: ELASTIC_NUM_SHARDS
              name: common-settings
        - name: OPENNMS_HTTP_USER
          value: admin
        - name: OPENNMS_HTTP_PASS
          valueFrom:
            secretKeyRef:
              key: OPENNMS_UI_ADMIN_PASSWORD
              name: onms-passwords
        - name: NUM_LISTENER_THREADS
          valueFrom:
            configMapKeyRef:
              key: KAFKA_NUM_PARTITIONS
              name: common-settings
        - name: JAEGER_AGENT_HOST
          value: onms-tracing-agent.opennms.svc.cluster.local
        image: bash
        imagePullPolicy: IfNotPresent
        name: init-config
        volumeMounts:
        - mountPath: /etc-overlay
          name: etc-overlay
        - mountPath: /init.sh
          name: init-scripts
          subPath: onms-sentinel-init.sh
      terminationGracePeriodSeconds: 60
      volumes:
      - emptyDir: {}
        name: etc-overlay
      - configMap:
          name: init-scripts
        name: init-scripts
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  labels:
    app: zk
  name: zk
  namespace: opennms
spec:
  podManagementPolicy: OrderedReady
  replicas: 1
  selector:
    matchLabels:
      app: zk
  serviceName: zookeeper
  template:
    metadata:
      labels:
        app: zk
    spec:
      containers:
      - env:
        - name: ZOO_SERVERS
          value: server.1=zk-0.zookeeper.opennms.svc.cluster.local:2888:3888;2181
        - name: ZOO_STANDALONE_ENABLED
          value: "true"
        - name: TZ
          valueFrom:
            configMapKeyRef:
              key: TIMEZONE
              name: common-settings
        - name: ZOO_4LW_COMMANDS_WHITELIST
          value: '*'
        - name: ZOO_TICK_TIME
          value: "2000"
        - name: ZOO_INIT_LIMIT
          value: "10"
        - name: ZOO_SYNC_LIMIT
          value: "5"
        - name: JMXLOCALONLY
          value: "false"
        - name: JMXDISABLE
          value: "false"
        - name: JMXPORT
          value: "9998"
        - name: JMXAUTH
          value: "false"
        - name: JMXSSL
          value: "false"
        - name: MEM_TOTAL_MB
          valueFrom:
            resourceFieldRef:
              divisor: 1Mi
              resource: requests.memory
        - name: JVMFLAGS
          value: -Xms$(MEM_TOTAL_MB)m -Xmx$(MEM_TOTAL_MB)m
        image: zookeeper:3.5
        imagePullPolicy: IfNotPresent
        livenessProbe:
          initialDelaySeconds: 30
          periodSeconds: 60
          tcpSocket:
            port: client
        name: zk
        ports:
        - containerPort: 2181
          name: client
        - containerPort: 2888
          name: server
        - containerPort: 3888
          name: leader-election
        - containerPort: 8080
          name: admin
        - containerPort: 9998
          name: jmx
        readinessProbe:
          exec:
            command:
            - sh
            - -c
            - '[ "imok" = "$(echo ruok | nc 127.0.0.1 2181)" ]'
          initialDelaySeconds: 10
          periodSeconds: 10
        resources:
          limits:
            cpu: 200m
            memory: 256Mi
          requests:
            cpu: 100m
            memory: 128Mi
        volumeMounts:
        - mountPath: /data
          name: data
      initContainers:
      - command:
        - sh
        - -c
        - ORD=${HOSTNAME##*-}; MYID=$((ORD+1)); echo $MYID > /data/myid
        image: busybox
        name: generate-zooid
        volumeMounts:
        - mountPath: /data
          name: data
      securityContext:
        fsGroup: 1000
        runAsUser: 1000
      terminationGracePeriodSeconds: 300
  updateStrategy:
    type: RollingUpdate
  volumeClaimTemplates:
  - metadata:
      name: data
    spec:
      accessModes:
      - ReadWriteOnce
      resources:
        requests:
          storage: 4Gi
---
apiVersion: batch/v1
kind: CronJob
metadata:
  labels:
    app: curator
  name: curator-cron
  namespace: opennms
spec:
  jobTemplate:
    metadata:
      labels:
        app: curator
      name: curator-job
    spec:
      template:
        metadata:
          labels:
            app: curator
        spec:
          containers:
          - args:
            - --config
            - /config/config.yaml
            - /config/actions.yaml
            env:
            - name: TZ
              value: America/New_York
            image: bobrik/curator:5.8.1
            name: delete-indices
            volumeMounts:
            - mountPath: /config
              name: curator-config
          restartPolicy: Never
          volumes:
          - configMap:
              name: curator-config
            name: curator-config
  schedule: 0 3 * * *
---
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: zk-pdb
  namespace: opennms
spec:
  maxUnavailable: 1
  selector:
    matchLabels:
      app: zk
---
apiVersion: batch/v1
kind: Job
metadata:
  labels:
    app: grafana
  name: helm-init
  namespace: opennms
spec:
  template:
    spec:
      containers:
      - command:
        - sh
        - /onms-helm-init.sh
        env:
        - name: TZ
          valueFrom:
            configMapKeyRef:
              key: TIMEZONE
              name: common-settings
        - name: DOMAIN
          valueFrom:
            configMapKeyRef:
              key: DOMAIN
              name: common-settings
        - name: GF_SECURITY_ADMIN_PASSWORD
          valueFrom:
            secretKeyRef:
              key: GRAFANA_UI_ADMIN_PASSWORD
              name: onms-passwords
        - name: GRAFANA_URL
          value: http://grafana.opennms.svc.cluster.local:3000
        - name: ONMS_URL
          value: https://onmsui.$(DOMAIN)/opennms
        - name: ONMS_USER
          value: admin
        - name: ONMS_PASSWD
          valueFrom:
            secretKeyRef:
              key: OPENNMS_UI_ADMIN_PASSWORD
              name: onms-passwords
        image: curlimages/curl
        imagePullPolicy: IfNotPresent
        name: init-config
        volumeMounts:
        - mountPath: /onms-helm-init.sh
          name: init-scripts
          subPath: onms-helm-init.sh
      restartPolicy: Never
      volumes:
      - configMap:
          name: init-scripts
        name: init-scripts
  ttlSecondsAfterFinished: 120
---
apiVersion: batch/v1
kind: Job
metadata:
  labels:
    app: kafka
  name: kafka-init
  namespace: opennms
spec:
  template:
    spec:
      containers:
      - command:
        - bash
        - create-topics.sh
        env:
        - name: TZ
          valueFrom:
            configMapKeyRef:
              key: TIMEZONE
              name: common-settings
        - name: KAFKA_SERVER
          value: kafka.opennms.svc.cluster.local
        - name: KAFKA_CLIENT_USER
          valueFrom:
            secretKeyRef:
              key: KAFKA_CLIENT_USER
              name: onms-passwords
        - name: KAFKA_CLIENT_PASSWORD
          valueFrom:
            secretKeyRef:
              key: KAFKA_CLIENT_PASSWORD
              name: onms-passwords
        - name: INSTANCE_ID
          valueFrom:
            configMapKeyRef:
              key: OPENNMS_INSTANCE_ID
              name: common-settings
        - name: CREATE_TOPICS
          value: $(INSTANCE_ID)_nodes $(INSTANCE_ID)_alarms $(INSTANCE_ID)_alarms_feedback
            $(INSTANCE_ID)_alec_inventory $(INSTANCE_ID)_edges $(INSTANCE_ID)_opennms_flows
        - name: KAFKA_CFG_DEFAULT_REPLICATION_FACTOR
          valueFrom:
            configMapKeyRef:
              key: KAFKA_REPLICATION_FACTOR
              name: common-settings
        - name: KAFKA_CFG_NUM_PARTITIONS
          valueFrom:
            configMapKeyRef:
              key: KAFKA_NUM_PARTITIONS
              name: common-settings
        image: bitnami/kafka:2.8.1
        imagePullPolicy: IfNotPresent
        name: init-config
        volumeMounts:
        - mountPath: /create-topics.sh
          name: init-scripts
          subPath: create-topics.sh
      initContainers:
      - env:
        - name: TARGETS
          value: kafka.opennms.svc.cluster.local:9092
        - name: TIMEOUT
          value: "900"
        image: waisbrot/wait
        imagePullPolicy: IfNotPresent
        name: dependencies
      restartPolicy: Never
      volumes:
      - configMap:
          name: init-scripts
        name: init-scripts
  ttlSecondsAfterFinished: 120
---
apiVersion: cert-manager.io/v1
kind: Certificate
metadata:
  name: minion-cert
  namespace: opennms
spec:
  commonName: minion
  issuerRef:
    group: cert-manager.io
    kind: Issuer
    name: onms-ca-issuer
  privateKey:
    algorithm: RSA
    size: 2048
  secretName: minion-cert
  subject:
    organizations:
    - OpenNMS
---
apiVersion: cert-manager.io/v1
kind: Certificate
metadata:
  name: onms-ca
  namespace: opennms
spec:
  commonName: onms-system
  isCA: true
  issuerRef:
    group: cert-manager.io
    kind: Issuer
    name: selfsigned-issuer
  secretName: onms-ca
  subject:
    organizations:
    - OpenNMS
---
apiVersion: cert-manager.io/v1
kind: Issuer
metadata:
  name: letsencrypt-prod
  namespace: opennms
spec:
  acme:
    email: agalue@opennms.org
    privateKeySecretRef:
      name: letsencrypt-prod
    server: https://acme-v02.api.letsencrypt.org/directory
    solvers:
    - http01:
        ingress:
          class: nginx
---
apiVersion: cert-manager.io/v1
kind: Issuer
metadata:
  name: onms-ca-issuer
  namespace: opennms
spec:
  ca:
    secretName: onms-ca
---
apiVersion: cert-manager.io/v1
kind: Issuer
metadata:
  name: selfsigned-issuer
  namespace: opennms
spec:
  selfSigned: {}
---
apiVersion: jaegertracing.io/v1
kind: Jaeger
metadata:
  name: onms-tracing
  namespace: opennms
spec:
  ingress:
    enabled: false
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  annotations:
    cert-manager.io/issuer: onms-ca-issuer
    kubernetes.io/ingress.class: nginx
    nginx.ingress.kubernetes.io/auth-tls-pass-certificate-to-upstream: "false"
    nginx.ingress.kubernetes.io/auth-tls-secret: opennms/onms-ca
    nginx.ingress.kubernetes.io/auth-tls-verify-client: "on"
    nginx.ingress.kubernetes.io/auth-tls-verify-depth: "1"
    nginx.ingress.kubernetes.io/backend-protocol: GRPC
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
  name: grpc-ingress
  namespace: opennms
spec:
  rules:
  - host: grpc.test
    http:
      paths:
      - backend:
          service:
            name: grpc-server
            port:
              number: 8990
        path: /
        pathType: Prefix
  tls:
  - hosts:
    - grpc.test
    secretName: grpc-ingress-cert
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  annotations:
    acme.cert-manager.io/http01-edit-in-place: "true"
    cert-manager.io/issuer: onms-ca-issuer
    ingress.kubernetes.io/affinity: cookie
    ingress.kubernetes.io/session-cookie-hash: sha1
    ingress.kubernetes.io/session-cookie-name: route
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
  name: onms-ingress
  namespace: opennms
spec:
  ingressClassName: nginx
  rules:
  - host: onms.test
    http:
      paths:
      - backend:
          service:
            name: opennms-core
            port:
              number: 8980
        path: /
        pathType: Prefix
  - host: grafana.test
    http:
      paths:
      - backend:
          service:
            name: grafana
            port:
              number: 3000
        path: /
        pathType: Prefix
  - host: kafka-manager.test
    http:
      paths:
      - backend:
          service:
            name: kafka-manager
            port:
              number: 9000
        path: /
        pathType: Prefix
  - host: kibana.test
    http:
      paths:
      - backend:
          service:
            name: kibana
            port:
              number: 5601
        path: /
        pathType: Prefix
  - host: tracing.test
    http:
      paths:
      - backend:
          service:
            name: onms-tracing-query
            port:
              number: 16686
        path: /
        pathType: Prefix
  tls:
  - hosts:
    - onms.test
    - grafana.test
    - kafka-manager.test
    - kibana.test
    - tracing.test
    secretName: opennms-ingress-cert
